"""
VulnerabilityClassifier - Model for classifying vulnerabilities and reducing false positives.
This module provides the model and utilities for training, saving, and loading models
used by the IntelligentAnalyzer to classify true and false positive vulnerabilities.
"""

import os
import pickle
import logging
import numpy as np
import pandas as pd
from typing import List, Dict, Any, Optional, Tuple
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Настройка логирования
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('VulnerabilityClassifier')

class VulnerabilityClassifier:
    """
    Класс для классификации уязвимостей на истинные и ложные срабатывания.
    """
    
    def __init__(self, model_path: Optional[str] = None):
        """
        Инициализация классификатора уязвимостей.
        
        Args:
            model_path (str, optional): Путь к сохраненной модели для загрузки
        """
        self.model = None
        self.vectorizer = None
        self.feature_columns = ['alert', 'url', 'risk', 'confidence', 'description', 'param']
        self.target_column = 'is_false_positive'
        
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)
            logger.info(f"Модель загружена из {model_path}")
        else:
            logger.info("Модель не загружена. Необходимо обучить новую модель.")
    
    def preprocess_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """
        Предобработка данных для модели.
        
        Args:
            df (pd.DataFrame): DataFrame с данными уязвимостей
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: Кортеж (X, y) с признаками и целевыми переменными
        """
        # Проверка наличия необходимых столбцов
        for col in self.feature_columns + [self.target_column]:
            if col not in df.columns:
                logger.error(f"Отсутствует столбец '{col}' в данных")
                raise ValueError(f"Отсутствует столбец '{col}' в данных")
        
        # Текстовые признаки (объединение description и alert)
        X_text = df['description'] + ' ' + df['alert']
        
        # Векторизация текста
        if self.vectorizer is None:
            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
            X_text_vec = self.vectorizer.fit_transform(X_text)
        else:
            X_text_vec = self.vectorizer.transform(X_text)
        
        # Категориальные признаки
        X_cat = pd.get_dummies(df[['risk', 'confidence']], drop_first=True)
        
        # Параметр уязвимости (наличие или отсутствие)
        df['has_param'] = df['param'].apply(lambda x: 0 if pd.isna(x) or x == '' else 1)
        
        # Объединение всех признаков
        X = np.hstack((X_cat.values, X_text_vec.toarray(), df[['has_param']].values))
        
        # Целевая переменная
        y = df[self.target_column].values
        
        return X, y
    
    def train(self, train_df: pd.DataFrame, test_size: float = 0.3) -> Dict[str, float]:
        """
        Обучение модели классификации уязвимостей.
        
        Args:
            train_df (pd.DataFrame): DataFrame с данными для обучения
            test_size (float): Доля тестовой выборки
            
        Returns:
            Dict[str, float]: Метрики качества модели
        """
        logger.info("Обучение модели классификации уязвимостей...")
        
        # Предобработка данных
        X, y = self.preprocess_data(train_df)
        
        # Разделение на обучающую и тестовую выборки
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
        
        # Обучение модели
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            random_state=42
        )
        self.model.fit(X_train, y_train)
        
        # Оценка модели
        y_pred = self.model.predict(X_test)
        
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1_score': f1_score(y_test, y_pred, zero_division=0)
        }
        
        logger.info(f"Модель обучена. Метрики: {metrics}")
        return metrics
    
    def predict(self, data: pd.DataFrame) -> np.ndarray:
        """
        Предсказание ложных срабатываний для новых данных.
        
        Args:
            data (pd.DataFrame): DataFrame с данными уязвимостей
            
        Returns:
            np.ndarray: Массив предсказаний (True для ложных срабатываний, False для истинных)
        """
        if self.model is None or self.vectorizer is None:
            logger.error("Модель не обучена. Сначала обучите модель.")
            raise ValueError("Модель не обучена")
        
        # Создаем DataFrame с необходимыми столбцами
        required_columns = list(set(self.feature_columns) - {self.target_column})
        for col in required_columns:
            if col not in data.columns:
                data[col] = ''
        
        # Предобработка
        X, _ = self.preprocess_data(data.assign(**{self.target_column: 0}))  # Временный столбец
        
        # Предсказание
        predictions = self.model.predict(X)
        probabilities = self.model.predict_proba(X)[:, 1]  # Вероятность класса "ложное срабатывание"
        
        return predictions, probabilities
    
    def save_model(self, path: str) -> bool:
        """
        Сохранение модели в файл.
        
        Args:
            path (str): Путь для сохранения модели
            
        Returns:
            bool: True при успешном сохранении, иначе False
        """
        if self.model is None or self.vectorizer is None:
            logger.error("Нет обученной модели для сохранения")
            return False
        
        try:
            model_data = {
                'model': self.model,
                'vectorizer': self.vectorizer,
                'feature_columns': self.feature_columns,
                'target_column': self.target_column
            }
            
            with open(path, 'wb') as f:
                pickle.dump(model_data, f)
            
            logger.info(f"Модель сохранена в {path}")
            return True
        except Exception as e:
            logger.error(f"Ошибка при сохранении модели: {e}")
            return False
    
    def load_model(self, path: str) -> bool:
        """
        Загрузка модели из файла.
        
        Args:
            path (str): Путь к файлу модели
            
        Returns:
            bool: True при успешной загрузке, иначе False
        """
        try:
            with open(path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            self.vectorizer = model_data['vectorizer']
            self.feature_columns = model_data.get('feature_columns', self.feature_columns)
            self.target_column = model_data.get('target_column', self.target_column)
            
            logger.info(f"Модель успешно загружена из {path}")
            return True
        except Exception as e:
            logger.error(f"Ошибка при загрузке модели: {e}")
            return False


class CVSSCalculator:
    """
    Класс для расчета оценок CVSS (Common Vulnerability Scoring System).
    """
    
    @staticmethod
    def calculate_cvss_score(alert_type: str, risk: str, confidence: str) -> Dict[str, float]:
        """
        Расчет оценки CVSS для уязвимости.
        
        Args:
            alert_type (str): Тип оповещения/уязвимости
            risk (str): Уровень риска (High, Medium, Low, Informational)
            confidence (str): Уровень уверенности (High, Medium, Low)
            
        Returns:
            Dict[str, float]: Словарь с оценками CVSS
        """
        # Базовые оценки для разных уровней риска
        base_scores = {
            'High': 8.0,
            'Medium': 5.5,
            'Low': 3.0,
            'Informational': 0.0
        }
        
        # Корректировка в зависимости от типа оповещения
        type_adjustments = {
            'SQL Injection': 1.5,
            'Cross Site Scripting': 1.0,
            'Remote Code Execution': 2.0,
            'Command Injection': 1.8,
            'Path Traversal': 1.0,
            'Remote File Inclusion': 1.5,
            'Local File Inclusion': 1.2,
            'Authentication Bypass': 1.7,
            'Information Disclosure': 0.8,
            'Security Misconfiguration': 0.5,
            'Insecure Direct Object Reference': 0.7,
            'Cross-Site Request Forgery': 0.9,
            'Unvalidated Redirects and Forwards': 0.5,
            'Missing Security Headers': 0.2,
            'Content Security Policy': 0.3,
            'Cookie Issues': 0.4
        }
        
        # Корректировка в зависимости от уверенности
        confidence_factor = {
            'High': 1.0,
            'Medium': 0.8,
            'Low': 0.6
        }
        
        # Расчет базовой оценки
        base_score = base_scores.get(risk, 0.0)
        
        # Корректировка на основе типа оповещения
        for alert_key, adjustment in type_adjustments.items():
            if alert_key.lower() in alert_type.lower():
                base_score += adjustment
                break
        
        # Применение фактора уверенности
        conf_factor = confidence_factor.get(confidence, 0.7)
        
        # Ограничение максимальной оценки до 10.0
        adjusted_score = min(base_score * conf_factor, 10.0)
        
        # Расчет оценок эксплуатируемости и воздействия
        exploitability_score = adjusted_score * 0.4
        impact_score = adjusted_score * 0.6
        
        return {
            'base_score': round(adjusted_score, 1),
            'exploitability_score': round(exploitability_score, 1),
            'impact_score': round(impact_score, 1),
            'temporal_score': round(adjusted_score * 0.9, 1),  # Временная оценка (приблизительно)
            'environmental_score': round(adjusted_score, 1)    # Без учета окружения
        }


class PresetFilter:
    """
    Статический класс с предустановленными правилами фильтрации для известных ложных срабатываний.
    """
    
    # Правила фильтрации для известных ложных срабатываний
    FILTER_RULES = [
        {
            'alert_name': 'X-Content-Type-Options Header Missing',
            'url_pattern': r'.*\.(jpg|jpeg|png|gif|css|js|woff|ttf|svg)$',
            'confidence_threshold': 'Medium',
            'action': 'filter'
        },
        {
            'alert_name': 'Cookie No HttpOnly Flag',
            'param_pattern': r'^analytics_|^tracking_|^_ga|^_gid',
            'action': 'reduce_risk'
        },
        {
            'alert_name': 'Cross-Domain JavaScript Source File Inclusion',
            'url_pattern': r'^https://cdn\.|^https://analytics\.|^https://apis\.',
            'action': 'filter'
        },
        {
            'alert_name': 'Content Security Policy (CSP) Header Not Set',
            'url_pattern': r'.*\.(jpg|jpeg|png|gif|css|js|woff|ttf|svg|json)$',
            'action': 'filter'
        },
        {
            'alert_name': 'Timestamp Disclosure',
            'action': 'reduce_risk'
        },
        {
            'alert_name': 'Information Disclosure - Suspicious Comments',
            'evidence_pattern': r'todo|fixme|note',
            'confidence_threshold': 'Low',
            'action': 'filter'
        },
        {
            'alert_name': 'Server Leaks Information via "X-Powered-By" HTTP Response Header Field(s)',
            'action': 'reduce_risk'
        },
        {
            'alert_name': 'X-Frame-Options Header Not Set',
            'url_pattern': r'.*\.(jpg|jpeg|png|gif|css|js|woff|ttf|svg|json)$',
            'action': 'filter'
        }
    ]
    
    @staticmethod
    def apply_filters(alerts: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], int]:
        """
        Применение предустановленных правил фильтрации к оповещениям.
        
        Args:
            alerts (List[Dict[str, Any]]): Список оповещений
            
        Returns:
            Tuple[List[Dict[str, Any]], int]: Кортеж (отфильтрованные оповещения, количество отфильтрованных)
        """
        import re
        
        filtered_alerts = []
        filtered_count = 0
        
        for alert in alerts:
            should_filter = False
            
            # Проверка каждого правила
            for rule in PresetFilter.FILTER_RULES:
                if rule.get('alert_name', '') == alert.get('name', ''):
                    
                    # Проверка URL-паттерна, если он задан в правиле
                    if 'url_pattern' in rule and alert.get('url', ''):
                        if re.match(rule['url_pattern'], alert['url']):
                            if rule['action'] == 'filter':
                                should_filter = True
                                break
                            elif rule['action'] == 'reduce_risk':
                                # Понижение уровня риска
                                if alert.get('risk', '') == 'High':
                                    alert['risk'] = 'Medium'
                                elif alert.get('risk', '') == 'Medium':
                                    alert['risk'] = 'Low'
                    
                    # Проверка параметра, если он задан в правиле
                    if 'param_pattern' in rule and alert.get('param', ''):
                        if re.match(rule['param_pattern'], alert['param']):
                            if rule['action'] == 'filter':
                                should_filter = True
                                break
                            elif rule['action'] == 'reduce_risk':
                                # Понижение уровня риска
                                if alert.get('risk', '') == 'High':
                                    alert['risk'] = 'Medium'
                                elif alert.get('risk', '') == 'Medium':
                                    alert['risk'] = 'Low'
                    
                    # Проверка свидетельства, если оно задано в правиле
                    if 'evidence_pattern' in rule and alert.get('evidence', ''):
                        if re.search(rule['evidence_pattern'], alert['evidence'], re.IGNORECASE):
                            if rule['action'] == 'filter':
                                should_filter = True
                                break
                            elif rule['action'] == 'reduce_risk':
                                # Понижение уровня риска
                                if alert.get('risk', '') == 'High':
                                    alert['risk'] = 'Medium'
                                elif alert.get('risk', '') == 'Medium':
                                    alert['risk'] = 'Low'
                    
                    # Общее действие для правила без условий
                    if 'url_pattern' not in rule and 'param_pattern' not in rule and 'evidence_pattern' not in rule:
                        if rule['action'] == 'filter':
                            should_filter = True
                            break
                        elif rule['action'] == 'reduce_risk':
                            # Понижение уровня риска
                            if alert.get('risk', '') == 'High':
                                alert['risk'] = 'Medium'
                            elif alert.get('risk', '') == 'Medium':
                                alert['risk'] = 'Low'
            
            # Добавление оповещения, если оно не отфильтровано
            if not should_filter:
                filtered_alerts.append(alert)
            else:
                filtered_count += 1
        
        return filtered_alerts, filtered_count