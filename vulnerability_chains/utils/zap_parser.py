"""
ZAPAlertParser - Parser for OWASP ZAP alerts and scan results.
"""

import json
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path

from ..models import Vulnerability
from ..constants import RiskLevel

logger = logging.getLogger(__name__)


# Noise vulnerabilities to filter out (not exploitable in chains)
NOISE_VULNERABILITIES = {
    # Tool-specific issues
    "ZAP is Out of Date",
    "ZAP Out of Date",

    # Low-value informational findings
    "Timestamp Disclosure",
    "Timestamp Disclosure - Unix",
    "Re-examine Cache-control Directives",

    # Duplicate/redundant headers (already covered by "Missing Security Headers")
    # Only filter if very specific and not adding value
}


class ZAPAlertParser:
    """
    Parser for converting OWASP ZAP alerts to Vulnerability objects.
    Filters out noise vulnerabilities that don't contribute to exploitable chains.
    """

    def __init__(self, filter_noise: bool = True):
        """
        Initialize the parser.

        Args:
            filter_noise: If True, filter out noise vulnerabilities (default: True)
        """
        self.parsed_count = 0
        self.skipped_count = 0
        self.filter_noise = filter_noise

    def parse_zap_report(self, report_file: str) -> List[Vulnerability]:
        """
        Parse OWASP ZAP JSON report file.

        Args:
            report_file: Path to ZAP JSON report file

        Returns:
            List of Vulnerability objects

        Raises:
            FileNotFoundError: If report file doesn't exist
            json.JSONDecodeError: If report file is not valid JSON
        """
        logger.info(f"Parsing ZAP report: {report_file}")

        try:
            with open(report_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            vulnerabilities = self._parse_report_data(data)

            logger.info(
                f"Parsed {len(vulnerabilities)} vulnerabilities "
                f"(parsed: {self.parsed_count}, skipped: {self.skipped_count})"
            )

            return vulnerabilities

        except FileNotFoundError:
            logger.error(f"Report file not found: {report_file}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in report file: {e}")
            raise
        except Exception as e:
            logger.error(f"Error parsing report: {e}")
            raise

    def parse_zap_alerts(self, alerts: List[Dict[str, Any]]) -> List[Vulnerability]:
        """
        Parse list of ZAP alert dictionaries.

        Args:
            alerts: List of alert dictionaries from ZAP

        Returns:
            List of Vulnerability objects
        """
        logger.info(f"Parsing {len(alerts)} ZAP alerts")

        vulnerabilities = []
        self.parsed_count = 0
        self.skipped_count = 0

        for alert in alerts:
            try:
                vuln = self._parse_alert(alert)
                if vuln:
                    vulnerabilities.append(vuln)
                    self.parsed_count += 1
                else:
                    self.skipped_count += 1
            except Exception as e:
                logger.warning(f"Error parsing alert: {e}")
                self.skipped_count += 1

        logger.info(
            f"Parsed {len(vulnerabilities)} vulnerabilities "
            f"(parsed: {self.parsed_count}, skipped: {self.skipped_count})"
        )

        return vulnerabilities

    def _parse_report_data(self, data: Dict[str, Any]) -> List[Vulnerability]:
        """
        Extract vulnerabilities from ZAP report data structure.

        Args:
            data: Parsed JSON report data

        Returns:
            List of Vulnerability objects
        """
        vulnerabilities = []
        self.parsed_count = 0
        self.skipped_count = 0

        # ZAP report structure can vary, handle multiple formats
        # Standard ZAP JSON report format
        if 'site' in data:
            sites = data['site'] if isinstance(data['site'], list) else [data['site']]

            for site in sites:
                alerts = site.get('alerts', [])
                for alert in alerts:
                    try:
                        # ZAP alerts may have multiple instances
                        instances = alert.get('instances', [])
                        if instances:
                            # Create vulnerability for each instance
                            # Don't copy entire alert dict - memory optimization
                            for instance in instances:
                                vuln = self._parse_alert_with_instance(alert, instance)
                                if vuln:
                                    vulnerabilities.append(vuln)
                                    self.parsed_count += 1
                        else:
                            vuln = self._parse_alert(alert)
                            if vuln:
                                vulnerabilities.append(vuln)
                                self.parsed_count += 1
                    except Exception as e:
                        logger.warning(f"Error parsing alert: {e}")
                        self.skipped_count += 1

        # Alternative format (alerts at root level)
        elif 'alerts' in data:
            alerts = data['alerts']
            vulnerabilities = self.parse_zap_alerts(alerts)

        # Simple list of alerts
        elif isinstance(data, list):
            vulnerabilities = self.parse_zap_alerts(data)

        return vulnerabilities

    def _parse_alert(self, alert: Dict[str, Any]) -> Optional[Vulnerability]:
        """
        Parse a single ZAP alert into a Vulnerability object.

        Args:
            alert: Alert dictionary from ZAP

        Returns:
            Vulnerability object or None if invalid/filtered
        """
        # Get alert name for filtering
        alert_name = alert.get('name') or alert.get('alert', '')

        # Filter noise vulnerabilities
        if self.filter_noise and alert_name in NOISE_VULNERABILITIES:
            logger.debug("Filtered noise vulnerability: %s", alert_name)
            self.skipped_count += 1
            return None

        # Skip informational alerts if configured
        # Handle both 'risk' string and 'riskcode' numeric formats
        risk = alert.get('risk')
        if not risk:
            riskcode = alert.get('riskcode', '0')
            risk_map = {'0': 'Informational', '1': 'Low', '2': 'Medium', '3': 'High'}
            risk = risk_map.get(str(riskcode), 'Informational')

        if risk == 'Informational' and not self._include_informational():
            return None

        try:
            return Vulnerability.from_zap_alert(alert)
        except Exception as e:
            logger.warning(f"Error creating vulnerability from alert: {e}")
            return None

    def _parse_alert_with_instance(
        self,
        alert: Dict[str, Any],
        instance: Dict[str, Any]
    ) -> Optional[Vulnerability]:
        """
        Parse ZAP alert with specific instance data.

        Memory-efficient: doesn't copy entire alert dict for each instance.

        Args:
            alert: Base alert dict (shared data: name, description, solution, etc.)
            instance: Instance-specific data (uri, param, attack, evidence, etc.)

        Returns:
            Vulnerability object or None if invalid/filtered
        """
        # Get alert name for filtering
        alert_name = alert.get('name') or alert.get('alert', '')

        # Filter noise vulnerabilities
        if self.filter_noise and alert_name in NOISE_VULNERABILITIES:
            logger.debug("Filtered noise vulnerability: %s", alert_name)
            self.skipped_count += 1
            return None

        # Skip informational alerts
        risk = alert.get('risk')
        if not risk:
            riskcode = alert.get('riskcode', '0')
            risk_map = {'0': 'Informational', '1': 'Low', '2': 'Medium', '3': 'High'}
            risk = risk_map.get(str(riskcode), 'Informational')

        if risk == 'Informational' and not self._include_informational():
            return None

        try:
            # Merge only necessary fields
            # Instance fields override base alert fields
            merged = {
                # Base alert fields (heavy, shared across instances)
                'name': alert.get('name'),
                'description': alert.get('description'),
                'solution': alert.get('solution'),
                'reference': alert.get('reference'),
                'risk': alert.get('risk'),
                'riskcode': alert.get('riskcode'),
                'confidence': alert.get('confidence'),
                'pluginid': alert.get('pluginid'),
                'cweid': alert.get('cweid'),
                'wascid': alert.get('wascid'),

                # Instance-specific fields (light, unique per instance)
                'uri': instance.get('uri'),
                'param': instance.get('param'),
                'attack': instance.get('attack'),
                'evidence': instance.get('evidence'),
                'method': instance.get('method'),
                'other': instance.get('other'),
            }

            return Vulnerability.from_zap_alert(merged)
        except Exception as e:
            logger.warning(f"Error creating vulnerability from alert+instance: {e}")
            return None

    def parse_from_zap_api(self, zap_api_response: Dict[str, Any]) -> List[Vulnerability]:
        """
        Parse vulnerabilities from ZAP API response.

        Args:
            zap_api_response: Response from ZAP API alerts endpoint

        Returns:
            List of Vulnerability objects
        """
        logger.info("Parsing ZAP API response")

        # ZAP API returns alerts in specific format
        alerts = zap_api_response.get('alerts', [])
        return self.parse_zap_alerts(alerts)

    def filter_by_risk(
        self,
        vulnerabilities: List[Vulnerability],
        min_risk: RiskLevel = RiskLevel.LOW
    ) -> List[Vulnerability]:
        """
        Filter vulnerabilities by minimum risk level.

        Args:
            vulnerabilities: List of vulnerabilities
            min_risk: Minimum risk level to include

        Returns:
            Filtered list of vulnerabilities
        """
        filtered = [
            v for v in vulnerabilities
            if v.risk.value >= min_risk.value
        ]

        logger.info(
            f"Filtered {len(vulnerabilities)} vulnerabilities to "
            f"{len(filtered)} with risk >= {min_risk.name}"
        )

        return filtered

    def filter_by_confidence(
        self,
        vulnerabilities: List[Vulnerability],
        min_confidence: str = 'Medium'
    ) -> List[Vulnerability]:
        """
        Filter vulnerabilities by minimum confidence level.

        Args:
            vulnerabilities: List of vulnerabilities
            min_confidence: Minimum confidence ('Low', 'Medium', 'High')

        Returns:
            Filtered list of vulnerabilities
        """
        confidence_order = {'Low': 0, 'Medium': 1, 'High': 2}
        min_conf_value = confidence_order.get(min_confidence, 0)

        filtered = [
            v for v in vulnerabilities
            if confidence_order.get(v.confidence, 0) >= min_conf_value
        ]

        logger.info(
            f"Filtered {len(vulnerabilities)} vulnerabilities to "
            f"{len(filtered)} with confidence >= {min_confidence}"
        )

        return filtered

    def deduplicate_vulnerabilities(
        self,
        vulnerabilities: List[Vulnerability]
    ) -> List[Vulnerability]:
        """
        Remove duplicate vulnerabilities based on unique identifiers.

        Args:
            vulnerabilities: List of vulnerabilities

        Returns:
            Deduplicated list
        """
        seen_ids = set()
        unique_vulns = []

        for vuln in vulnerabilities:
            if vuln.id not in seen_ids:
                unique_vulns.append(vuln)
                seen_ids.add(vuln.id)

        if len(unique_vulns) < len(vulnerabilities):
            logger.info(
                f"Removed {len(vulnerabilities) - len(unique_vulns)} duplicate vulnerabilities"
            )

        return unique_vulns

    def group_by_type(
        self,
        vulnerabilities: List[Vulnerability]
    ) -> Dict[str, List[Vulnerability]]:
        """
        Group vulnerabilities by type.

        Args:
            vulnerabilities: List of vulnerabilities

        Returns:
            Dictionary mapping vulnerability type to list of vulnerabilities
        """
        grouped = {}

        for vuln in vulnerabilities:
            if vuln.name not in grouped:
                grouped[vuln.name] = []
            grouped[vuln.name].append(vuln)

        logger.info(f"Grouped {len(vulnerabilities)} vulnerabilities into {len(grouped)} types")

        return grouped

    def get_statistics(self, vulnerabilities: List[Vulnerability]) -> Dict[str, Any]:
        """
        Get statistics about parsed vulnerabilities.

        Args:
            vulnerabilities: List of vulnerabilities

        Returns:
            Dictionary with statistics
        """
        if not vulnerabilities:
            return {
                'total': 0,
                'by_risk': {},
                'by_confidence': {},
                'by_type': {},
                'unique_urls': 0
            }

        # Count by risk
        by_risk = {}
        for vuln in vulnerabilities:
            risk_name = vuln.risk.name
            by_risk[risk_name] = by_risk.get(risk_name, 0) + 1

        # Count by confidence
        by_confidence = {}
        for vuln in vulnerabilities:
            conf = vuln.confidence
            by_confidence[conf] = by_confidence.get(conf, 0) + 1

        # Count by type
        by_type = {}
        for vuln in vulnerabilities:
            vuln_type = vuln.name
            by_type[vuln_type] = by_type.get(vuln_type, 0) + 1

        # Unique URLs
        unique_urls = len(set(v.url for v in vulnerabilities))

        return {
            'total': len(vulnerabilities),
            'by_risk': by_risk,
            'by_confidence': by_confidence,
            'by_type': by_type,
            'unique_urls': unique_urls
        }

    @staticmethod
    def _include_informational() -> bool:
        """
        Check if informational alerts should be included.

        Returns:
            True to include informational alerts
        """
        # Can be configured via environment variable or config file
        # For now, exclude informational by default
        return False

    def export_vulnerabilities(
        self,
        vulnerabilities: List[Vulnerability],
        output_file: str
    ) -> None:
        """
        Export vulnerabilities to JSON file.

        Args:
            vulnerabilities: List of vulnerabilities to export
            output_file: Output file path
        """
        try:
            output_data = {
                'vulnerabilities': [v.to_dict() for v in vulnerabilities],
                'statistics': self.get_statistics(vulnerabilities),
                'count': len(vulnerabilities)
            }

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)

            logger.info(f"Exported {len(vulnerabilities)} vulnerabilities to {output_file}")

        except Exception as e:
            logger.error(f"Error exporting vulnerabilities: {e}")
            raise

    def __repr__(self) -> str:
        """String representation of the parser."""
        return f"ZAPAlertParser(parsed={self.parsed_count}, skipped={self.skipped_count})"
