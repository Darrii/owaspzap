import json
import logging
from pathlib import Path

from ..models import Vulnerability
from ..constants import RiskLevel

logger = logging.getLogger(__name__)


NOISE_VULNERABILITIES = {
    "ZAP is Out of Date",
    "ZAP Out of Date",
    "Timestamp Disclosure",
    "Timestamp Disclosure - Unix",
    "Re-examine Cache-control Directives",
}


class ZAPAlertParser:
    def __init__(self, filter_noise=True):
        self.parsed_count = 0
        self.skipped_count = 0
        self.filter_noise = filter_noise

    def parse_zap_report(self, report_file):
        try:
            with open(report_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            vulnerabilities = self._parse_report_data(data)
            return vulnerabilities

        except FileNotFoundError:
            logger.error(f"Report file not found: {report_file}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in report file: {e}")
            raise
        except Exception as e:
            logger.error(f"Error parsing report: {e}")
            raise

    def parse_zap_alerts(self, alerts):
        vulnerabilities = []
        self.parsed_count = 0
        self.skipped_count = 0

        for alert in alerts:
            try:
                vuln = self._parse_alert(alert)
                if vuln:
                    vulnerabilities.append(vuln)
                    self.parsed_count += 1
                else:
                    self.skipped_count += 1
            except Exception as e:
                logger.warning(f"Error parsing alert: {e}")
                self.skipped_count += 1

        return vulnerabilities

    def _parse_report_data(self, data):
        vulnerabilities = []
        self.parsed_count = 0
        self.skipped_count = 0

        if 'site' in data:
            sites = data['site'] if isinstance(data['site'], list) else [data['site']]

            for site in sites:
                alerts = site.get('alerts', [])
                for alert in alerts:
                    try:
                        instances = alert.get('instances', [])
                        if instances:
                            for instance in instances:
                                vuln = self._parse_alert_with_instance(alert, instance)
                                if vuln:
                                    vulnerabilities.append(vuln)
                                    self.parsed_count += 1
                        else:
                            vuln = self._parse_alert(alert)
                            if vuln:
                                vulnerabilities.append(vuln)
                                self.parsed_count += 1
                    except Exception as e:
                        logger.warning(f"Error parsing alert: {e}")
                        self.skipped_count += 1

        elif 'alerts' in data:
            alerts = data['alerts']
            vulnerabilities = self.parse_zap_alerts(alerts)

        elif isinstance(data, list):
            vulnerabilities = self.parse_zap_alerts(data)

        return vulnerabilities

    def _parse_alert(self, alert):
        alert_name = alert.get('name') or alert.get('alert', '')

        if self.filter_noise and alert_name in NOISE_VULNERABILITIES:
            self.skipped_count += 1
            return None

        risk = alert.get('risk')
        if not risk:
            riskcode = alert.get('riskcode', '0')
            risk_map = {'0': 'Informational', '1': 'Low', '2': 'Medium', '3': 'High'}
            risk = risk_map.get(str(riskcode), 'Informational')

        if risk == 'Informational' and not self._include_informational():
            return None

        try:
            return Vulnerability.from_zap_alert(alert)
        except Exception as e:
            logger.warning(f"Error creating vulnerability from alert: {e}")
            return None

    def _parse_alert_with_instance(self, alert, instance):
        alert_name = alert.get('name') or alert.get('alert', '')

        if self.filter_noise and alert_name in NOISE_VULNERABILITIES:
            self.skipped_count += 1
            return None

        risk = alert.get('risk')
        if not risk:
            riskcode = alert.get('riskcode', '0')
            risk_map = {'0': 'Informational', '1': 'Low', '2': 'Medium', '3': 'High'}
            risk = risk_map.get(str(riskcode), 'Informational')

        if risk == 'Informational' and not self._include_informational():
            return None

        try:
            merged = {
                'name': alert.get('name'),
                'description': alert.get('description'),
                'solution': alert.get('solution'),
                'reference': alert.get('reference'),
                'risk': alert.get('risk'),
                'riskcode': alert.get('riskcode'),
                'confidence': alert.get('confidence'),
                'pluginid': alert.get('pluginid'),
                'cweid': alert.get('cweid'),
                'wascid': alert.get('wascid'),
                'uri': instance.get('uri'),
                'param': instance.get('param'),
                'attack': instance.get('attack'),
                'evidence': instance.get('evidence'),
                'method': instance.get('method'),
                'other': instance.get('other'),
            }

            return Vulnerability.from_zap_alert(merged)
        except Exception as e:
            logger.warning(f"Error creating vulnerability from alert+instance: {e}")
            return None

    def parse_from_zap_api(self, zap_api_response):
        alerts = zap_api_response.get('alerts', [])
        return self.parse_zap_alerts(alerts)

    def filter_by_risk(self, vulnerabilities, min_risk=RiskLevel.LOW):
        filtered = [
            v for v in vulnerabilities
            if v.risk.value >= min_risk.value
        ]
        return filtered

    def filter_by_confidence(self, vulnerabilities, min_confidence='Medium'):
        confidence_order = {'Low': 0, 'Medium': 1, 'High': 2}
        min_conf_value = confidence_order.get(min_confidence, 0)

        filtered = [
            v for v in vulnerabilities
            if confidence_order.get(v.confidence, 0) >= min_conf_value
        ]
        return filtered

    def deduplicate_vulnerabilities(self, vulnerabilities):
        seen_ids = set()
        unique_vulns = []

        for vuln in vulnerabilities:
            if vuln.id not in seen_ids:
                unique_vulns.append(vuln)
                seen_ids.add(vuln.id)

        return unique_vulns

    def group_by_type(self, vulnerabilities):
        grouped = {}

        for vuln in vulnerabilities:
            if vuln.name not in grouped:
                grouped[vuln.name] = []
            grouped[vuln.name].append(vuln)

        return grouped

    def get_statistics(self, vulnerabilities):
        if not vulnerabilities:
            return {
                'total': 0,
                'by_risk': {},
                'by_confidence': {},
                'by_type': {},
                'unique_urls': 0
            }

        by_risk = {}
        for vuln in vulnerabilities:
            risk_name = vuln.risk.name
            by_risk[risk_name] = by_risk.get(risk_name, 0) + 1

        by_confidence = {}
        for vuln in vulnerabilities:
            conf = vuln.confidence
            by_confidence[conf] = by_confidence.get(conf, 0) + 1

        by_type = {}
        for vuln in vulnerabilities:
            vuln_type = vuln.name
            by_type[vuln_type] = by_type.get(vuln_type, 0) + 1

        unique_urls = len(set(v.url for v in vulnerabilities))

        return {
            'total': len(vulnerabilities),
            'by_risk': by_risk,
            'by_confidence': by_confidence,
            'by_type': by_type,
            'unique_urls': unique_urls
        }

    @staticmethod
    def _include_informational():
        return False

    def export_vulnerabilities(self, vulnerabilities, output_file):
        try:
            output_data = {
                'vulnerabilities': [v.to_dict() for v in vulnerabilities],
                'statistics': self.get_statistics(vulnerabilities),
                'count': len(vulnerabilities)
            }

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)

        except Exception as e:
            logger.error(f"Error exporting vulnerabilities: {e}")
            raise
