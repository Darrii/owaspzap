"""
EnhancedChainDetector - Improved chain detection with probabilistic links,
context analysis, and transitive closure.
"""

from typing import List, Dict, Set, Tuple, Optional, TYPE_CHECKING
from dataclasses import dataclass, field
from collections import defaultdict
from datetime import datetime
import networkx as nx
import logging

if TYPE_CHECKING:
    from ..models import Vulnerability, VulnerabilityChain, ChainLink
    from .taxonomy import VulnerabilityTaxonomy
    from ..rules.probabilistic_rules import ProbabilisticRuleEngine
    from .context_analyzer import ContextAnalyzer

from ..models import VulnerabilityChain, ChainLink
from ..constants import ChainType

logger = logging.getLogger(__name__)


@dataclass
class EnhancedChainLink:
    """Enhanced edge with probability and metadata"""
    source_id: str
    target_id: str
    probability: float  # 0.0 - 1.0
    rule_ids: List[str]  # Which rules matched
    link_type: str  # "direct", "cluster", "transitive"
    metadata: Dict = field(default_factory=dict)

    @property
    def weight(self) -> float:
        """Weight for graph algorithms (invert probability)"""
        return 1.0 - self.probability


class EnhancedChainDetector:
    """
    Improved chain detector with probabilistic connections,
    contextual analysis, and transitive closure.
    """

    def __init__(
        self,
        taxonomy: 'VulnerabilityTaxonomy',
        rule_engine: 'ProbabilisticRuleEngine',
        context_analyzer: 'ContextAnalyzer',
        config: Optional[Dict] = None
    ):
        self.taxonomy = taxonomy
        self.rule_engine = rule_engine
        self.context_analyzer = context_analyzer

        # Configuration
        self.config = config or {}
        self.min_probability = self.config.get('min_probability', 0.3)
        self.enable_transitive = self.config.get('enable_transitive', True)
        self.max_transitive_depth = self.config.get('max_transitive_depth', 2)
        self.cluster_link_boost = self.config.get('cluster_link_boost', 1.2)
        self.enable_cluster_links = self.config.get('enable_cluster_links', True)

        # Graph
        self.graph = nx.DiGraph()
        self.links: Dict[Tuple[str, str], EnhancedChainLink] = {}

    def build_graph(self, vulnerabilities: List['Vulnerability']) -> nx.DiGraph:
        """Builds graph with probabilistic connections"""

        logger.info(f"Building enhanced graph for {len(vulnerabilities)} vulnerabilities")

        # Step 1: Add all nodes
        for vuln in vulnerabilities:
            self.graph.add_node(
                vuln.id,
                vulnerability=vuln,
                taxonomy=self.taxonomy.classify(vuln.name)
            )

        # Step 2: Direct links through rules
        direct_links = self._create_direct_links(vulnerabilities)
        logger.info(f"Created {len(direct_links)} direct links")

        # Step 3: Contextual analysis and cluster links
        if self.enable_cluster_links:
            cluster_links = self._create_cluster_links(vulnerabilities)
            logger.info(f"Created {len(cluster_links)} cluster links")
        else:
            logger.info("Cluster links disabled")

        # Step 4: Transitive links
        if self.enable_transitive:
            transitive_links = self._create_transitive_links()
            logger.info(f"Created {len(transitive_links)} transitive links")

        # Step 5: Aggregate all links
        self._aggregate_links()

        logger.info(f"Final graph: {self.graph.number_of_nodes()} nodes, {self.graph.number_of_edges()} edges")

        return self.graph

    def _create_direct_links(self, vulnerabilities: List['Vulnerability']) -> List[EnhancedChainLink]:
        """Creates direct links through probabilistic rules"""
        links = []

        # O(N²) pass through all pairs
        for i, source in enumerate(vulnerabilities):
            for target in vulnerabilities[i+1:]:
                # Source → Target
                results = self.rule_engine.calculate_link_probability(source, target)
                for rule_id, prob, metadata in results:
                    if prob >= self.min_probability:
                        link = EnhancedChainLink(
                            source_id=source.id,
                            target_id=target.id,
                            probability=prob,
                            rule_ids=[rule_id],
                            link_type="direct",
                            metadata=metadata
                        )
                        self._add_link(link)
                        links.append(link)

                # Target → Source (reverse direction)
                results = self.rule_engine.calculate_link_probability(target, source)
                for rule_id, prob, metadata in results:
                    if prob >= self.min_probability:
                        link = EnhancedChainLink(
                            source_id=target.id,
                            target_id=source.id,
                            probability=prob,
                            rule_ids=[rule_id],
                            link_type="direct",
                            metadata=metadata
                        )
                        self._add_link(link)
                        links.append(link)

        return links

    def _create_cluster_links(self, vulnerabilities: List['Vulnerability']) -> List[EnhancedChainLink]:
        """Creates links within clusters"""
        links = []

        # Analyze context
        clusters = self.context_analyzer.analyze(vulnerabilities)

        for cluster in clusters:
            for source_id, target_id, strength in cluster.internal_links:
                # Boost link if it already exists from rules
                existing = self.links.get((source_id, target_id))

                if existing:
                    # Strengthen existing link
                    new_prob = min(existing.probability * self.cluster_link_boost, 1.0)
                    existing.probability = new_prob
                    existing.metadata['cluster_boost'] = cluster.cluster_type
                else:
                    # Create new link
                    link = EnhancedChainLink(
                        source_id=source_id,
                        target_id=target_id,
                        probability=strength,
                        rule_ids=[f"cluster_{cluster.cluster_type}"],
                        link_type="cluster",
                        metadata={
                            'cluster_id': cluster.cluster_id,
                            'cluster_type': cluster.cluster_type,
                            'shared_context': cluster.shared_context
                        }
                    )
                    self._add_link(link)
                    links.append(link)

        return links

    def _create_transitive_links(self) -> List[EnhancedChainLink]:
        """
        Creates transitive links.
        If A→B (p1) and B→C (p2), create A→C (p1*p2*decay)
        """
        links = []
        decay_factor = 0.7  # Reduce probability for transitivity

        # Use Floyd-Warshall-like approach
        for depth in range(self.max_transitive_depth):
            new_links = []

            for node_b in self.graph.nodes():
                # All incoming edges to B
                in_edges = list(self.graph.in_edges(node_b, data=True))
                # All outgoing edges from B
                out_edges = list(self.graph.out_edges(node_b, data=True))

                for in_edge in in_edges:
                    node_a = in_edge[0]
                    prob_ab = in_edge[2].get('probability', 0.5)

                    for out_edge in out_edges:
                        node_c = out_edge[1]
                        prob_bc = out_edge[2].get('probability', 0.5)

                        # Skip self-loops
                        if node_a == node_c:
                            continue

                        # Calculate transitive probability
                        trans_prob = prob_ab * prob_bc * decay_factor

                        # Check minimum threshold
                        if trans_prob < self.min_probability * 0.8:  # Slightly lower for transitive
                            continue

                        # Check if link A→C already exists
                        existing = self.links.get((node_a, node_c))

                        if existing:
                            # Update only if transitive probability is higher
                            if trans_prob > existing.probability:
                                existing.probability = trans_prob
                                existing.link_type = "transitive"
                                existing.metadata['via'] = node_b
                        else:
                            link = EnhancedChainLink(
                                source_id=node_a,
                                target_id=node_c,
                                probability=trans_prob,
                                rule_ids=["transitive"],
                                link_type="transitive",
                                metadata={'via': node_b, 'depth': depth + 1}
                            )
                            new_links.append(link)

            # Add new transitive links
            for link in new_links:
                self._add_link(link)
                links.append(link)

        return links

    def _add_link(self, link: EnhancedChainLink):
        """Adds link to graph and dictionary"""
        key = (link.source_id, link.target_id)

        # If link exists, take maximum probability
        if key in self.links:
            existing = self.links[key]
            if link.probability > existing.probability:
                self.links[key] = link
        else:
            self.links[key] = link

        # Add to NetworkX graph
        self.graph.add_edge(
            link.source_id,
            link.target_id,
            probability=link.probability,
            weight=link.weight,
            rule_ids=link.rule_ids,
            link_type=link.link_type,
            metadata=link.metadata
        )

    def _aggregate_links(self):
        """Final aggregation and normalization of links"""
        # Remove weak links
        edges_to_remove = []
        for u, v, data in self.graph.edges(data=True):
            if data.get('probability', 0) < self.min_probability:
                edges_to_remove.append((u, v))

        for u, v in edges_to_remove:
            self.graph.remove_edge(u, v)
            key = (u, v)
            if key in self.links:
                del self.links[key]

    def find_chains(
        self,
        min_length: int = 2,
        max_length: int = 5,
        min_chain_probability: float = 0.3
    ) -> List['VulnerabilityChain']:
        """
        Finds all vulnerability chains in the graph.
        Uses modified DFS accounting for probabilities.
        """
        chains = []

        # Find all paths using DFS
        for start_node in self.graph.nodes():
            visited = {start_node}
            self._dfs_chains(
                current=start_node,
                path=[start_node],
                path_probability=1.0,
                visited=visited,
                chains=chains,
                min_length=min_length,
                max_length=max_length,
                min_prob=min_chain_probability
            )

        # Sort by score
        chains.sort(key=lambda c: c.risk_score, reverse=True)

        # Remove duplicates and subchains
        chains = self._deduplicate_chains(chains)

        # Filter low-value chains (info-only, non-exploitable)
        chains = self._filter_low_value_chains(chains)

        logger.info(f"Found {len(chains)} valuable chains")
        return chains

    def _dfs_chains(
        self,
        current: str,
        path: List[str],
        path_probability: float,
        visited: Set[str],
        chains: List,
        min_length: int,
        max_length: int,
        min_prob: float,
        max_chains: int = None
    ):
        """Recursive DFS for finding chains"""

        # Check limit INSIDE recursion to stop early
        if max_chains and len(chains) >= max_chains:
            return

        # If path is long enough, save as chain
        if len(path) >= min_length and path_probability >= min_prob:
            chain = self._create_chain_from_path(path, path_probability)
            if chain:
                chains.append(chain)
                # Check limit again after adding
                if max_chains and len(chains) >= max_chains:
                    return

        # If reached maximum length, stop
        if len(path) >= max_length:
            return

        # Continue search
        for neighbor in self.graph.successors(current):
            if neighbor not in visited:
                edge_data = self.graph.edges[current, neighbor]
                edge_prob = edge_data.get('probability', 0.5)

                new_path_prob = path_probability * edge_prob

                # Pruning: if probability too low, don't continue
                if new_path_prob < min_prob * 0.5:
                    continue

                visited.add(neighbor)
                self._dfs_chains(
                    current=neighbor,
                    path=path + [neighbor],
                    path_probability=new_path_prob,
                    visited=visited,
                    chains=chains,
                    min_length=min_length,
                    max_length=max_length,
                    min_prob=min_prob,
                    max_chains=max_chains
                )
                visited.remove(neighbor)

                # Check limit after each neighbor to stop early
                if max_chains and len(chains) >= max_chains:
                    return

    def _create_chain_from_path(self, path: List[str], probability: float) -> Optional['VulnerabilityChain']:
        """Creates chain object from graph path"""
        vulnerabilities = []
        links = []

        for node_id in path:
            node_data = self.graph.nodes[node_id]
            vuln = node_data.get('vulnerability')
            if vuln:
                vulnerabilities.append(vuln)

        # Check for cycles (repeated vulnerability IDs)
        vuln_ids = [v.id for v in vulnerabilities]
        if len(vuln_ids) != len(set(vuln_ids)):
            # Contains duplicates - skip this chain
            return None

        # Create ChainLink objects from graph edges (use graph data, not cached links)
        for i in range(len(path) - 1):
            source_id = path[i]
            target_id = path[i+1]

            # Get edge data from graph (NOT from self.links which may have stale max probability)
            if self.graph.has_edge(source_id, target_id):
                edge_data = self.graph.edges[source_id, target_id]
                edge_prob = edge_data.get('probability', 0.5)
                rule_ids = edge_data.get('rule_ids', [])
                link_type = edge_data.get('link_type', 'unknown')

                # Get source and target vulnerability objects
                source_vuln = vulnerabilities[i] if i < len(vulnerabilities) else None
                target_vuln = vulnerabilities[i+1] if i+1 < len(vulnerabilities) else None

                if not source_vuln or not target_vuln:
                    continue

                # Convert to regular ChainLink
                chain_link = ChainLink(
                    source=source_vuln,
                    target=target_vuln,
                    rule_name=rule_ids[0] if rule_ids else "unknown",
                    description=f"{link_type} link (p={edge_prob:.2f})",
                    exploitability=edge_prob,
                    confidence=edge_prob
                )
                links.append(chain_link)

        if len(vulnerabilities) < 2:
            return None

        # Calculate chain risk
        risk_score = self._calculate_chain_risk(vulnerabilities, links, probability)

        # Determine chain type
        chain_type = self._determine_chain_type(vulnerabilities)

        # Generate impact description
        vuln_names = [v.name for v in vulnerabilities]
        impact_description = " → ".join(vuln_names)

        # Generate exploitation steps
        exploitation_steps = [
            f"Step {i+1}: Exploit {link.description}"
            for i, link in enumerate(links)
        ]

        return VulnerabilityChain(
            id=f"enhanced_chain_{abs(hash(tuple(path))) % 100000}",
            vulnerabilities=vulnerabilities,
            links=links,
            chain_type=chain_type,
            risk_score=risk_score,
            confidence=probability,
            impact_description=impact_description,
            exploitation_steps=exploitation_steps,
            detected_at=datetime.now()
        )

    def _calculate_chain_risk(
        self,
        vulns: List['Vulnerability'],
        links: List[ChainLink],
        probability: float
    ) -> float:
        """
        Calculates normalized chain risk score (0-100).

        Formula components:
        - Base severity: Max 30 points (highest risk vuln × 10)
        - Exploitability: Max 30 points (avg link exploitability × 30)
        - Chain length: Max 20 points (length bonus, capped at 5 vulns)
        - Confidence: Max 20 points (probability × 20)

        Returns:
            Risk score between 0-100
        """
        if not vulns:
            return 0.0

        # 1. Base Severity Score (0-30 points)
        # Use maximum vulnerability risk (not sum to avoid inflation)
        max_risk = max(int(v.risk.value) for v in vulns)
        base_severity_score = (max_risk / 3.0) * 30.0  # Normalize HIGH(3) = 30 points

        # 2. Exploitability Score (0-30 points)
        # Average exploitability of all links
        if links:
            avg_exploitability = sum(link.exploitability for link in links) / len(links)
            exploitability_score = avg_exploitability * 30.0
        else:
            exploitability_score = 15.0  # Neutral if no links

        # 3. Chain Length Score (0-20 points)
        # Logarithmic scaling: longer chains are more complex but not linearly riskier
        # Length 2 = 10pts, Length 3 = 15pts, Length 4 = 18pts, Length 5+ = 20pts
        if len(vulns) == 1:
            length_score = 0.0
        elif len(vulns) == 2:
            length_score = 10.0
        elif len(vulns) == 3:
            length_score = 15.0
        elif len(vulns) == 4:
            length_score = 18.0
        else:
            length_score = 20.0

        # 4. Confidence Score (0-20 points)
        # Directly from probability
        confidence_score = probability * 20.0

        # Final score (0-100)
        risk_score = base_severity_score + exploitability_score + length_score + confidence_score

        # Ensure bounds [0, 100]
        risk_score = max(0.0, min(100.0, risk_score))

        return round(risk_score, 2)

    def _determine_chain_type(self, vulns: List['Vulnerability']) -> ChainType:
        """Determines chain type from vulnerabilities"""
        names = [v.name.lower() for v in vulns]

        # Chain patterns
        if any('session' in n or 'cookie' in n for n in names) and any('xss' in n for n in names):
            return ChainType.SESSION_HIJACKING

        if any('sql' in n or 'injection' in n for n in names):
            return ChainType.DATA_EXFILTRATION

        if any('auth' in n or 'access' in n for n in names):
            return ChainType.PRIVILEGE_ESCALATION

        if any('command' in n or 'rce' in n or 'exec' in n for n in names):
            return ChainType.REMOTE_CODE_EXECUTION

        if any('disclosure' in n or 'directory' in n for n in names):
            return ChainType.INFORMATION_GATHERING

        return ChainType.COMPOUND_EXPLOIT

    @staticmethod
    def _classify_chain_severity(risk_score: float) -> str:
        """
        Classify chain severity based on normalized risk score.

        Severity levels:
        - CRITICAL: 90-100 (exploitable, high-impact chains)
        - HIGH: 70-89 (dangerous chains with clear exploit path)
        - MEDIUM: 40-69 (moderate risk, may require multiple conditions)
        - LOW: 0-39 (low risk, informational or difficult to exploit)

        Args:
            risk_score: Normalized risk score (0-100)

        Returns:
            Severity level string
        """
        if risk_score >= 90:
            return "CRITICAL"
        elif risk_score >= 70:
            return "HIGH"
        elif risk_score >= 40:
            return "MEDIUM"
        else:
            return "LOW"

    def _deduplicate_chains(self, chains: List['VulnerabilityChain']) -> List['VulnerabilityChain']:
        """Removes duplicates and subchains"""
        if not chains:
            return []

        unique_chains = []
        seen_paths = set()

        for chain in chains:
            # Use ordered tuple of IDs for exact path matching
            path_tuple = tuple(v.id for v in chain.vulnerabilities)

            # Skip if we've seen this exact path
            if path_tuple in seen_paths:
                continue

            # Also check if this is a subpath of an existing path
            is_subpath = False
            for seen_path in list(seen_paths):
                # Check if current path is contained in seen_path
                if self._is_subpath_of(path_tuple, seen_path):
                    is_subpath = True
                    break
                # Check if seen_path is contained in current path (remove the smaller one)
                if self._is_subpath_of(seen_path, path_tuple):
                    seen_paths.discard(seen_path)
                    unique_chains = [c for c in unique_chains
                                   if tuple(v.id for v in c.vulnerabilities) != seen_path]

            if not is_subpath:
                seen_paths.add(path_tuple)
                unique_chains.append(chain)

        return unique_chains

    @staticmethod
    def _filter_low_value_chains(chains: List['VulnerabilityChain']) -> List['VulnerabilityChain']:
        """
        Filter out chains that are unlikely to be exploitable or useful.

        Low-value chain patterns:
        - All vulnerabilities are LOW risk (info disclosure only)
        - Chain consists only of non-exploitable types (headers, info disclosure)
        - No HIGH or CRITICAL vulnerabilities in chain

        Args:
            chains: List of chains to filter

        Returns:
            Filtered list of valuable chains
        """
        valuable_chains = []

        # Non-exploitable vulnerability types (can be part of chain, but not entire chain)
        non_exploitable_types = {
            'missing security headers',
            'server leaks information',
            'information disclosure',
            'x-powered-by',
            'x-content-type',
            'anti-clickjacking',
        }

        for chain in chains:
            # Check if chain has at least one HIGH risk vuln (MEDIUM alone isn't enough)
            has_high_vuln = any(
                v.risk.value >= 3  # HIGH or CRITICAL
                for v in chain.vulnerabilities
            )

            # For shorter chains (2-3), require HIGH vuln
            if len(chain) <= 3 and not has_high_vuln:
                continue

            # For longer chains (4+), allow if has MEDIUM+ vuln and not all info
            if len(chain) >= 4:
                has_medium_vuln = any(v.risk.value >= 2 for v in chain.vulnerabilities)
                if not has_medium_vuln:
                    continue

                # Check if chain is entirely non-exploitable types
                vuln_names_lower = [v.name.lower() for v in chain.vulnerabilities]
                all_non_exploitable = all(
                    any(non_exp in name for non_exp in non_exploitable_types)
                    for name in vuln_names_lower
                )

                if all_non_exploitable:
                    continue  # Skip pure info disclosure chains

            valuable_chains.append(chain)

        return valuable_chains

    @staticmethod
    def _is_subpath_of(subpath: Tuple[str, ...], path: Tuple[str, ...]) -> bool:
        """Check if subpath is contained within path as consecutive elements"""
        if len(subpath) > len(path):
            return False

        # Check if subpath appears as consecutive elements in path
        for i in range(len(path) - len(subpath) + 1):
            if path[i:i+len(subpath)] == subpath:
                return True

        return False

    def __repr__(self) -> str:
        return f"EnhancedChainDetector({self.graph.number_of_nodes()} nodes, {self.graph.number_of_edges()} edges)"
