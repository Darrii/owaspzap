"""
ProbabilisticRuleEngine - Probabilistic link creation instead of binary yes/no.

Base probabilities are calibrated using a Bayesian hybrid model that combines:
  - Expert prior (60% weight)
  - NVD empirical data from 10,000 CVEs via MLE (25% weight)
  - Metasploit module graph from 3,048 modules (15% weight)

See vulnerability_chains/rules/markov_calibration.py for details.
"""

from dataclasses import dataclass, field
from typing import List, Dict, Callable, Tuple, TYPE_CHECKING
from urllib.parse import urlparse
from collections import defaultdict
import logging
import re

from .markov_calibration import calibrate_by_name

if TYPE_CHECKING:
    from ..models import Vulnerability
    from ..core.taxonomy import VulnerabilityTaxonomy

logger = logging.getLogger(__name__)


@dataclass
class RuleEngineConfig:
    """Configuration for ProbabilisticRuleEngine behavior"""
    # Minimum probability threshold for link creation
    min_link_probability: float = 0.3

    # Maximum cumulative boost multiplier to prevent probability overflow
    max_boost_multiplier: float = 2.5

    # Enable semantic similarity calculation from taxonomy
    enable_semantic_similarity: bool = True

    # Enable taxonomy-based matching constraints
    enable_taxonomy_matching: bool = True


@dataclass
class ProbabilisticRule:
    """Rule with multiple factors affecting probability"""
    rule_id: str
    name: str

    # Base probability of link (if all conditions met)
    base_probability: float = 0.5

    # Factors that increase probability
    boosting_factors: List[Tuple[str, Callable, float]] = field(default_factory=list)
    # Format: (name, check_function, multiplier)

    # Factors that decrease probability
    penalty_factors: List[Tuple[str, Callable, float]] = field(default_factory=list)

    # Minimum taxonomy match level (category, subcategory, specific)
    min_taxonomy_match: str = "category"


class ProbabilisticRuleEngine:
    """
    Rule engine with probabilistic inference.
    Instead of binary "yes/no" returns probability of link.
    """

    # Precompiled regex patterns for performance optimization
    VERSION_PATTERN = re.compile(r'/v\d+/')
    STAGE_PATTERN = re.compile(r'/(beta|alpha)/')
    NUMERIC_ID_PATTERNS = [
        re.compile(r'/\d+(?:/|$)'),      # /123/ or /123
        re.compile(r'[?&]id=\d+'),       # ?id=123 or &id=123
        re.compile(r'[?&]user_?id=\d+'), # ?user_id=123
        re.compile(r'[?&]account=\d+'),  # ?account=123
    ]

    def __init__(self, taxonomy: 'VulnerabilityTaxonomy', config: RuleEngineConfig = None):
        self.taxonomy = taxonomy
        self.config = config or RuleEngineConfig()
        self.rules: List[ProbabilisticRule] = []
        self.error_stats: Dict[str, int] = defaultdict(int)
        self._build_rules()
        self._apply_markov_calibration()

    def _apply_markov_calibration(self):
        """
        Calibrate base_probability of every rule using the Bayesian hybrid model.

        For each rule the source and target vulnerability types are inferred from
        the rule name (e.g. "SQL Injection → Data Exfiltration" → sql_injection,
        info_disclosure).  The calibration function combines NVD empirical data,
        Metasploit module statistics, and the expert prior with weights 0.25/0.15/0.60.

        Rules whose name contains no recognisable keyword are left unchanged.
        """
        calibrated = 0
        for rule in self.rules:
            # Split rule name on common separators to get source and target halves
            name = rule.name
            for sep in [" → ", " to ", " + ", " enables ", "/"]:
                if sep in name:
                    parts = name.split(sep, 1)
                    src_text = parts[0].strip()
                    tgt_text = parts[1].strip()
                    new_prob = calibrate_by_name(src_text, tgt_text, rule.base_probability)
                    if abs(new_prob - rule.base_probability) > 0.001:
                        logger.debug(
                            "Calibrated rule %s: %.3f → %.3f (src=%r, tgt=%r)",
                            rule.rule_id, rule.base_probability, new_prob,
                            src_text, tgt_text
                        )
                        rule.base_probability = new_prob
                        calibrated += 1
                    break  # stop after first separator match

        logger.info("Markov calibration applied to %d/%d rules", calibrated, len(self.rules))

    def _build_rules(self):
        """Creates set of probabilistic rules"""

        # Rule 1: Cookie issues amplify each other
        self.rules.append(ProbabilisticRule(
            rule_id="COOKIE_SYNERGY",
            name="Cookie Issues Synergy",
            base_probability=0.7,
            boosting_factors=[
                ("same_cookie", lambda s, t: s.param == t.param and s.param, 1.5),
                ("same_endpoint", lambda s, t: self._same_endpoint(s, t), 1.3),
                ("both_high_risk", lambda s, t: int(s.risk.value) >= 2 and int(t.risk.value) >= 2, 1.2),
            ],
            penalty_factors=[
                ("different_domain", lambda s, t: not self._same_domain(s, t), 0.3),
            ],
            min_taxonomy_match="subcategory"
        ))

        # Rule 2: Misconfig headers → XSS amplification
        self.rules.append(ProbabilisticRule(
            rule_id="HEADER_XSS_AMPLIFY",
            name="Missing Headers Amplify XSS",
            base_probability=0.6,
            boosting_factors=[
                ("csp_missing", lambda s, t: "csp" in s.name.lower(), 1.8),
                ("same_origin", lambda s, t: self._same_domain(s, t), 1.4),
                ("xss_confirmed", lambda s, t: t.confidence >= 2, 1.3),
            ],
            penalty_factors=[
                ("different_app", lambda s, t: not self._same_path_prefix(s, t), 0.5),
            ],
            min_taxonomy_match="category"
        ))

        # Rule 3: XSS → Session Hijacking (merged with Rule 15 and 34)
        self.rules.append(ProbabilisticRule(
            rule_id="XSS_SESSION_HIJACK",
            name="XSS to Session Hijacking / Cookie Theft",
            base_probability=0.9,
            boosting_factors=[
                ("xss_confirmed", lambda s, t: any(x in s.name.lower() for x in ["xss", "cross site scripting", "reflected", "stored", "dom xss"]), 1.9),
                ("httponly_missing", lambda s, t: self._has_httponly_issue(s, t) or ("cookie" in t.name.lower() and "httponly" in t.name.lower() and "no" in t.name.lower()), 1.8),
                ("stored_xss", lambda s, t: "stored" in s.name.lower(), 1.6),
                ("same_domain", lambda s, t: self._same_domain(s, t), 1.5),
                ("session_cookie", lambda s, t: any(x in (t.param or "").lower() for x in ["session", "phpsessid", "jsessionid", "aspsessionid"]) or any(x in (s.param or "").lower() for x in ["session", "phpsessid", "jsessionid"]), 1.4),
            ],
            penalty_factors=[
                ("httponly_set", lambda s, t: not self._has_httponly_issue(s, t), 0.3),
                ("different_domain", lambda s, t: not self._same_domain(s, t), 0.2),
            ],
            min_taxonomy_match=None
        ))

        # Rule 4: Information Disclosure → further attacks
        self.rules.append(ProbabilisticRule(
            rule_id="INFO_DISCLOSURE_CHAIN",
            name="Info Disclosure Enables Attack",
            base_probability=0.5,
            boosting_factors=[
                ("reveals_paths", lambda s, t: self._reveals_paths(s), 1.6),
                ("reveals_tech", lambda s, t: self._reveals_technology(s), 1.4),
                ("target_needs_info", lambda s, t: self._needs_information(t), 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match="category"
        ))

        # Rule 5: Privilege Escalation pattern
        self.rules.append(ProbabilisticRule(
            rule_id="PRIVILEGE_ESCALATION",
            name="Privilege Escalation Chain",
            base_probability=0.4,
            boosting_factors=[
                ("auth_bypass_source", lambda s, t: "auth" in s.name.lower() or "access" in s.name.lower(), 1.6),
                ("admin_target", lambda s, t: "/admin" in (t.url or ""), 1.8),
                ("different_auth_level", lambda s, t: self._different_auth_levels(s, t), 1.5),
            ],
            penalty_factors=[
                ("same_auth_level", lambda s, t: not self._different_auth_levels(s, t), 0.5),
            ],
            min_taxonomy_match="category"
        ))

        # Rule 6: Security Headers complement each other
        self.rules.append(ProbabilisticRule(
            rule_id="HEADER_SYNERGY",
            name="Missing Security Headers Synergy",
            base_probability=0.65,
            boosting_factors=[
                ("same_domain", lambda s, t: self._same_domain(s, t), 1.4),
                ("both_misconfig", lambda s, t: "header" in s.name.lower() and "header" in t.name.lower(), 1.5),
                ("related_protection", lambda s, t: self._related_protections(s, t), 1.3),
            ],
            penalty_factors=[],
            min_taxonomy_match="subcategory"
        ))

        # ========== MODERN VULNERABILITY CHAINS (2023-2025) ==========

        # Rule 7: SSRF → Cloud Metadata Access (OWASP API 2023)
        self.rules.append(ProbabilisticRule(
            rule_id="SSRF_CLOUD_METADATA",
            name="SSRF to Cloud Metadata Theft",
            base_probability=0.9,
            boosting_factors=[
                ("ssrf_confirmed", lambda s, t: "ssrf" in s.name.lower(), 1.6),
                ("cloud_metadata", lambda s, t: any(x in t.name.lower() for x in ["metadata", "aws", "imds", "azure", "gcp"]), 1.8),
                ("internal_access", lambda s, t: "169.254.169.254" in (t.url or "") or "metadata" in (t.url or ""), 2.0),
            ],
            penalty_factors=[
                ("no_cloud", lambda s, t: not self._is_cloud_environment(s, t), 0.4),
            ],
            min_taxonomy_match=None  # Cross-category chain: ssrf → cloud_native
        ))

        # Rule 8: BOLA/IDOR → Mass Data Exfiltration (OWASP API 2023 #1)
        self.rules.append(ProbabilisticRule(
            rule_id="BOLA_MASS_EXFILTRATION",
            name="BOLA to Mass Data Exfiltration",
            base_probability=0.85,
            boosting_factors=[
                ("bola_or_idor", lambda s, t: any(x in s.name.lower() for x in ["bola", "idor", "authorization"]), 1.7),
                ("sequential_ids", lambda s, t: self._has_sequential_ids(s), 1.5),
                ("api_endpoint", lambda s, t: "/api/" in (s.url or ""), 1.4),
                ("user_data", lambda s, t: any(x in (t.url or "").lower() for x in ["/user", "/profile", "/account", "/data"]), 1.6),
            ],
            penalty_factors=[
                ("requires_auth", lambda s, t: "authenticated" in s.description.lower() if s.description else False, 0.7),
            ],
            min_taxonomy_match=None  # Cross-category: api_security → misconfig/other
        ))

        # Rule 9: GraphQL Batching → Rate Limit Bypass → Account Takeover
        self.rules.append(ProbabilisticRule(
            rule_id="GRAPHQL_BATCHING_TAKEOVER",
            name="GraphQL Batching to Account Takeover",
            base_probability=0.8,
            boosting_factors=[
                ("graphql_detected", lambda s, t: "graphql" in s.name.lower() or "/graphql" in (s.url or ""), 1.8),
                ("batching_enabled", lambda s, t: "batch" in s.name.lower() or "introspection" in s.name.lower(), 1.6),
                ("rate_limit_missing", lambda s, t: "rate" in t.name.lower() or "limit" in t.name.lower(), 1.5),
                ("auth_endpoint", lambda s, t: any(x in (t.url or "").lower() for x in ["/login", "/auth", "/token", "/otp"]), 1.7),
            ],
            penalty_factors=[
                ("rate_limit_present", lambda s, t: "rate limit" in t.description.lower() if t.description else False, 0.3),
            ],
            min_taxonomy_match=None  # Cross-category: graphql → misconfig
        ))

        # Rule 10: Prompt Injection → LLM Data Leakage (OWASP LLM 2025 #1)
        self.rules.append(ProbabilisticRule(
            rule_id="PROMPT_INJECTION_DATA_LEAK",
            name="Prompt Injection to LLM Data Disclosure",
            base_probability=0.75,
            boosting_factors=[
                ("prompt_injection", lambda s, t: "prompt" in s.name.lower() or "injection" in s.name.lower(), 1.8),
                ("llm_endpoint", lambda s, t: any(x in (s.url or "").lower() for x in ["/chat", "/ai", "/completion", "/generate"]), 1.6),
                ("data_disclosure", lambda s, t: any(x in t.name.lower() for x in ["disclosure", "leak", "data", "pii"]), 1.7),
                ("system_prompt_access", lambda s, t: "system" in t.name.lower() or "training" in t.name.lower(), 1.5),
            ],
            penalty_factors=[
                ("input_sanitization", lambda s, t: "sanitiz" in s.description.lower() if s.description else False, 0.5),
            ],
            min_taxonomy_match=None  # Can match within llm_ai category
        ))

        # Rule 11: Container Escape → Cluster Compromise (Cloud Native 2024)
        self.rules.append(ProbabilisticRule(
            rule_id="CONTAINER_ESCAPE_CLUSTER",
            name="Container Escape to Cluster Compromise",
            base_probability=0.95,
            boosting_factors=[
                ("container_escape", lambda s, t: any(x in s.name.lower() for x in ["container", "escape", "breakout", "docker"]), 2.0),
                ("kubernetes", lambda s, t: any(x in t.name.lower() for x in ["kubernetes", "k8s", "cluster", "pod"]), 1.8),
                ("host_access", lambda s, t: "host" in t.name.lower() or "node" in t.name.lower(), 1.7),
                ("privileged_container", lambda s, t: "privileged" in s.description.lower() if s.description else False, 1.5),
            ],
            penalty_factors=[
                ("isolated", lambda s, t: "isolated" in s.description.lower() if s.description else False, 0.4),
            ],
            min_taxonomy_match=None  # Can match within cloud_native or cross-category
        ))

        # Rule 12: JWT/OAuth Misconfiguration → Authentication Bypass (Modern Auth 2024)
        self.rules.append(ProbabilisticRule(
            rule_id="JWT_OAUTH_BYPASS",
            name="JWT/OAuth Misconfiguration to Auth Bypass",
            base_probability=0.8,
            boosting_factors=[
                ("jwt_issue", lambda s, t: any(x in s.name.lower() for x in ["jwt", "token", "oauth", "bearer"]), 1.7),
                ("weak_signing", lambda s, t: any(x in s.name.lower() for x in ["none", "weak", "unsigned"]), 1.8),
                ("admin_access", lambda s, t: any(x in (t.url or "").lower() for x in ["/admin", "/internal", "/manage"]), 1.6),
                ("privilege_escalation", lambda s, t: "privilege" in t.name.lower() or "escalation" in t.name.lower(), 1.5),
            ],
            penalty_factors=[
                ("strong_validation", lambda s, t: "validated" in s.description.lower() if s.description else False, 0.4),
            ],
            min_taxonomy_match=None  # Cross-category: broken_auth → broken_access
        ))

        # Rule 13: Rate Limiting Missing → Brute Force → Credential Theft (merged with Rule 38)
        self.rules.append(ProbabilisticRule(
            rule_id="NO_RATE_LIMIT_BRUTEFORCE",
            name="Missing Rate Limit → Credential Stuffing/Brute Force",
            base_probability=0.8,
            boosting_factors=[
                ("no_rate_limit", lambda s, t: any(x in s.name.lower() for x in ["no rate limit", "rate limit bypass", "missing rate limit", "rate", "limit"]), 1.8),
                ("auth_endpoint", lambda s, t: any(x in (s.url or "").lower() for x in ["/login", "/auth", "/otp", "/verify", "/password", "/authentication"]) or any(x in (t.url or "").lower() for x in ["/login", "/password", "/authentication", "/otp", "/verify"]), 1.9),
                ("credential_context", lambda s, t: any(x in t.name.lower() for x in ["credential", "password", "account", "takeover"]), 1.7),
                ("lockout_missing", lambda s, t: "lockout" not in (s.description or "").lower(), 1.3),
            ],
            penalty_factors=[
                ("captcha_present", lambda s, t: "captcha" in (s.description or "").lower(), 0.5),
                ("rate_limit_present", lambda s, t: "rate limit" in (t.description or "").lower() if t.description else False, 0.3),
            ],
            min_taxonomy_match=None  # Cross-category: misconfig → broken_auth
        ))

        # Rule 14: BFLA → Privilege Escalation (OWASP API 2023 #5)
        self.rules.append(ProbabilisticRule(
            rule_id="BFLA_PRIVILEGE_ESCALATION",
            name="BFLA to Privilege Escalation",
            base_probability=0.85,
            boosting_factors=[
                ("bfla_detected", lambda s, t: "bfla" in s.name.lower() or "function level" in s.name.lower(), 1.8),
                ("authorization_missing", lambda s, t: "authorization" in s.name.lower(), 1.6),
                ("admin_function", lambda s, t: any(x in (t.url or "").lower() for x in ["/admin", "/delete", "/update", "/manage"]), 1.7),
                ("role_confusion", lambda s, t: "role" in t.name.lower(), 1.4),
            ],
            penalty_factors=[
                ("rbac_enforced", lambda s, t: "rbac" in (s.description or "").lower(), 0.4),
            ],
            min_taxonomy_match=None  # Cross-category: api_security → broken_access
        ))

        # ========== COOKIE SECURITY CHAIN RULES ==========
        # Note: Rule 15 merged into Rule 3 (XSS_SESSION_HIJACK)

        # Rule 16: Cookie without Secure + Mixed Content = MITM
        self.rules.append(ProbabilisticRule(
            rule_id="COOKIE_SECURE_MITM",
            name="Cookie without Secure + Mixed Content = MITM",
            base_probability=0.7,
            boosting_factors=[
                ("secure_missing", lambda s, t: "secure" in s.name.lower() and any(x in s.name.lower() for x in ["no", "without", "missing"]), 1.6),
                ("mixed_content", lambda s, t: any(x in t.name.lower() for x in ["mixed content", "http resource", "insecure"]), 1.7),
                ("same_domain", lambda s, t: self._same_domain(s, t), 1.4),
                ("sensitive_cookie", lambda s, t: any(x in (s.param or "").lower() for x in ["session", "auth", "token", "jwt"]), 1.5),
            ],
            penalty_factors=[
                ("https_only", lambda s, t: "https://" in (s.url or "") and "http://" not in (t.url or ""), 0.5),
            ],
            min_taxonomy_match=None
        ))

        # Rule 17: Cookie without SameSite + CSRF = Attack
        self.rules.append(ProbabilisticRule(
            rule_id="COOKIE_SAMESITE_CSRF",
            name="Cookie without SameSite + Sensitive Action = CSRF",
            base_probability=0.85,
            boosting_factors=[
                ("samesite_missing", lambda s, t: "samesite" in s.name.lower() and any(x in s.name.lower() for x in ["without", "not set", "missing"]), 1.7),
                ("csrf_vulnerable", lambda s, t: any(x in t.name.lower() for x in ["csrf", "cross-site request", "no anti-csrf"]), 1.8),
                ("same_domain", lambda s, t: self._same_domain(s, t), 1.4),
                ("state_changing", lambda s, t: any(x in (t.url or "").lower() for x in ["/change", "/update", "/delete", "/transfer", "/send"]), 1.5),
            ],
            penalty_factors=[
                ("csrf_token_present", lambda s, t: "csrf token" in (t.description or "").lower() if t.description else False, 0.3),
            ],
            min_taxonomy_match=None
        ))

        # Rule 18: Multiple Cookie Issues = Complete Session Compromise
        self.rules.append(ProbabilisticRule(
            rule_id="TRIPLE_COOKIE_VULNERABILITY",
            name="Cookie without HttpOnly + Secure + SameSite = Critical",
            base_probability=0.95,
            boosting_factors=[
                ("httponly_missing", lambda s, t: "httponly" in s.name.lower() and "no" in s.name.lower(), 1.8),
                ("secure_missing", lambda s, t: "secure" in t.name.lower() and any(x in t.name.lower() for x in ["no", "without", "missing"]), 1.9),
                ("same_cookie_param", lambda s, t: s.param and t.param and s.param == t.param, 2.0),
                ("session_cookie", lambda s, t: any(x in (s.param or "").lower() for x in ["session", "phpsessid", "jsessionid"]), 1.6),
            ],
            penalty_factors=[],
            min_taxonomy_match="subcategory"  # Both must be cookie misconfigurations
        ))

        # ========== HEADER SECURITY CHAIN RULES ==========

        # Rule 19: Missing CSP + XSS = Unrestricted XSS
        self.rules.append(ProbabilisticRule(
            rule_id="CSP_MISSING_ENABLES_XSS",
            name="Missing CSP + XSS = Unrestricted Script Execution",
            base_probability=0.85,
            boosting_factors=[
                ("csp_missing", lambda s, t: any(x in s.name.lower() for x in ["content-security-policy", "csp"]) and any(y in s.name.lower() for y in ["not set", "missing"]), 1.8),
                ("xss_present", lambda s, t: any(x in t.name.lower() for x in ["xss", "cross site scripting", "dom xss"]), 1.9),
                ("same_domain", lambda s, t: self._same_domain(s, t), 1.4),
                ("stored_xss", lambda s, t: "stored" in t.name.lower(), 1.5),
            ],
            penalty_factors=[
                ("csp_present", lambda s, t: "content-security-policy" in (s.description or "").lower() if s.description else False, 0.2),
            ],
            min_taxonomy_match=None  # Cross-category: misconfig → injection
        ))

        # Rule 20: Missing X-Frame-Options + Sensitive Form = Clickjacking
        self.rules.append(ProbabilisticRule(
            rule_id="XFRAME_TO_CLICKJACKING",
            name="Missing X-Frame-Options + Sensitive Form = Clickjacking",
            base_probability=0.75,
            boosting_factors=[
                ("xframe_missing", lambda s, t: "x-frame-options" in s.name.lower() and any(x in s.name.lower() for x in ["not set", "missing"]), 1.7),
                ("sensitive_endpoint", lambda s, t: any(x in (t.url or "").lower() for x in ["/settings", "/password", "/email", "/security", "/account"]), 1.8),
                ("state_changing", lambda s, t: any(x in (t.url or "").lower() for x in ["/change", "/update", "/delete"]), 1.6),
                ("no_csrf", lambda s, t: "csrf" in t.name.lower() or "no anti-csrf" in t.name.lower(), 1.5),
            ],
            penalty_factors=[
                ("xframe_present", lambda s, t: "x-frame-options" in (s.description or "").lower() if s.description else False, 0.3),
            ],
            min_taxonomy_match=None
        ))

        # Rule 21: CORS Misconfiguration + Sensitive Endpoint = Data Theft
        self.rules.append(ProbabilisticRule(
            rule_id="CORS_WILDCARD_DATA_THEFT",
            name="CORS wildcard + Sensitive Endpoint = Cross-Origin Data Theft",
            base_probability=0.9,
            boosting_factors=[
                ("cors_wildcard", lambda s, t: "cors" in s.name.lower() and any(x in s.name.lower() for x in ["*", "wildcard", "misconfiguration"]), 1.9),
                ("api_endpoint", lambda s, t: "/api/" in (t.url or ""), 1.6),
                ("sensitive_data", lambda s, t: any(x in (t.url or "").lower() for x in ["/user", "/profile", "/account", "/data", "/me"]), 1.7),
                ("credentials_allowed", lambda s, t: "credentials" in (s.description or "").lower() if s.description else False, 1.8),
            ],
            penalty_factors=[
                ("cors_restricted", lambda s, t: "restricted" in (s.description or "").lower() if s.description else False, 0.3),
            ],
            min_taxonomy_match=None
        ))

        # Rule 22: Missing HSTS + Cookie without Secure = SSL Stripping
        self.rules.append(ProbabilisticRule(
            rule_id="HSTS_MISSING_SSL_STRIP",
            name="Missing HSTS + Cookie without Secure = SSL Stripping Attack",
            base_probability=0.6,
            boosting_factors=[
                ("hsts_missing", lambda s, t: "hsts" in s.name.lower() or "strict-transport-security" in s.name.lower(), 1.6),
                ("cookie_insecure", lambda s, t: "cookie" in t.name.lower() and any(x in t.name.lower() for x in ["no secure", "without secure"]), 1.7),
                ("same_domain", lambda s, t: self._same_domain(s, t), 1.4),
                ("session_cookie", lambda s, t: any(x in (t.param or "").lower() for x in ["session", "auth", "token"]), 1.5),
            ],
            penalty_factors=[
                ("hsts_present", lambda s, t: "hsts" in (s.description or "").lower() if s.description else False, 0.4),
            ],
            min_taxonomy_match=None
        ))

        # Rule 23: Multiple Missing Headers = Expanded Attack Surface
        self.rules.append(ProbabilisticRule(
            rule_id="HEADER_COMBO_ATTACK_SURFACE",
            name="Multiple Missing Headers = Expanded Attack Surface",
            base_probability=0.7,
            boosting_factors=[
                ("csp_missing", lambda s, t: "csp" in s.name.lower() and "not set" in s.name.lower(), 1.5),
                ("xframe_missing", lambda s, t: "x-frame-options" in t.name.lower() and "not set" in t.name.lower(), 1.5),
                ("same_domain", lambda s, t: self._same_domain(s, t), 1.4),
                ("both_headers", lambda s, t: "header" in s.name.lower() and "header" in t.name.lower(), 1.6),
            ],
            penalty_factors=[],
            min_taxonomy_match="subcategory"
        ))

        # ========== INJECTION CHAIN RULES (HIGH IMPACT) ==========

        # Rule 24: SQL Injection → Data Breach
        self.rules.append(ProbabilisticRule(
            rule_id="SQLI_TO_DATA_BREACH",
            name="SQL Injection → Data Exfiltration/Breach",
            base_probability=0.95,
            boosting_factors=[
                ("sqli_confirmed", lambda s, t: any(x in s.name.lower() for x in ["sql injection", "sqli", "error based sql", "blind sql", "time based sql"]), 2.0),
                ("database_access", lambda s, t: any(x in t.name.lower() for x in ["information disclosure", "database", "sensitive data", "credential", "password"]), 1.9),
                ("high_confidence", lambda s, t: s.confidence and s.confidence.lower() in ["high", "confirmed"], 1.5),
                ("error_based", lambda s, t: "error" in s.name.lower(), 1.4),
            ],
            penalty_factors=[
                ("blind_sqli", lambda s, t: "blind" in s.name.lower() and "error" not in s.name.lower(), 0.8),
            ],
            min_taxonomy_match=None
        ))

        # Rule 25: XXE → SSRF → Internal Network Access
        self.rules.append(ProbabilisticRule(
            rule_id="XXE_TO_SSRF",
            name="XXE → SSRF → Internal Network Access",
            base_probability=0.85,
            boosting_factors=[
                ("xxe_present", lambda s, t: any(x in s.name.lower() for x in ["xxe", "xml external entity", "xml injection"]), 1.9),
                ("ssrf_or_internal", lambda s, t: any(x in t.name.lower() for x in ["ssrf", "server side request", "internal", "metadata"]), 1.8),
                ("xml_endpoint", lambda s, t: "/xml" in (s.url or "").lower() or "xml" in (s.param or "").lower(), 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 26: Command Injection → RCE
        self.rules.append(ProbabilisticRule(
            rule_id="COMMAND_INJECTION_RCE",
            name="OS Command Injection → Full Server Compromise",
            base_probability=0.95,
            boosting_factors=[
                ("cmd_injection", lambda s, t: any(x in s.name.lower() for x in ["os command injection", "command injection", "remote os command"]), 2.0),
                ("server_context", lambda s, t: any(x in t.name.lower() for x in ["server", "system", "shell", "rce", "execution"]), 1.9),
                ("high_confidence", lambda s, t: s.confidence and s.confidence.lower() == "high", 1.6),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 27: SSTI → RCE
        self.rules.append(ProbabilisticRule(
            rule_id="SSTI_TO_RCE",
            name="Server-Side Template Injection → RCE",
            base_probability=0.9,
            boosting_factors=[
                ("ssti_present", lambda s, t: any(x in s.name.lower() for x in ["ssti", "template injection", "server side template"]), 1.9),
                ("code_execution", lambda s, t: any(x in t.name.lower() for x in ["code execution", "server", "rce"]), 1.8),
                ("template_param", lambda s, t: any(x in (s.param or "").lower() for x in ["template", "tpl", "view"]), 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 28: LFI → Source Code Disclosure → Credentials
        self.rules.append(ProbabilisticRule(
            rule_id="LFI_TO_SOURCE_CODE",
            name="LFI → Source Code Disclosure → Credentials",
            base_probability=0.8,
            boosting_factors=[
                ("lfi_present", lambda s, t: any(x in s.name.lower() for x in ["lfi", "local file inclusion", "path traversal", "directory traversal"]), 1.8),
                ("sensitive_file", lambda s, t: any(x in t.name.lower() for x in ["credential", "config", "password", "key", "source code"]), 1.7),
                ("file_parameter", lambda s, t: any(x in (s.param or "").lower() for x in ["file", "path", "page", "include", "template"]), 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 29: Deserialization → RCE
        self.rules.append(ProbabilisticRule(
            rule_id="DESERIALIZATION_RCE",
            name="Insecure Deserialization → RCE",
            base_probability=0.9,
            boosting_factors=[
                ("deserialization", lambda s, t: any(x in s.name.lower() for x in ["deserialization", "unserialize", "pickle", "marshal"]), 1.9),
                ("rce_context", lambda s, t: any(x in t.name.lower() for x in ["rce", "code execution", "server"]), 1.8),
                ("java_or_php", lambda s, t: any(x in (s.url or "").lower() for x in [".jsp", ".php", ".do"]), 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # ========== AUTH & SESSION CHAIN RULES ==========

        # Rule 30: Session Fixation → Account Takeover
        self.rules.append(ProbabilisticRule(
            rule_id="SESSION_FIXATION_TAKEOVER",
            name="Session Fixation → Account Takeover",
            base_probability=0.75,
            boosting_factors=[
                ("session_fixation", lambda s, t: any(x in s.name.lower() for x in ["session fixation", "session id in url"]), 1.8),
                ("login_endpoint", lambda s, t: any(x in (t.url or "").lower() for x in ["/login", "/auth", "/signin"]), 1.7),
                ("session_context", lambda s, t: any(x in t.name.lower() for x in ["session", "authentication", "account"]), 1.6),
            ],
            penalty_factors=[
                ("session_regeneration", lambda s, t: "regenerat" in (s.description or "").lower() if s.description else False, 0.3),
            ],
            min_taxonomy_match=None
        ))

        # Rule 31: Broken Auth → Account Takeover
        self.rules.append(ProbabilisticRule(
            rule_id="BROKEN_AUTH_ACCOUNT_TAKEOVER",
            name="Password Reset Flaw/Auth Bypass → Account Takeover",
            base_probability=0.85,
            boosting_factors=[
                ("auth_bypass", lambda s, t: any(x in s.name.lower() for x in ["broken authentication", "password reset", "reset token", "host header injection", "auth bypass"]), 1.9),
                ("account_context", lambda s, t: any(x in t.name.lower() for x in ["account", "email", "password", "credential"]), 1.7),
                ("reset_endpoint", lambda s, t: any(x in (s.url or "").lower() for x in ["/forgot", "/reset", "/recover"]), 1.6),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 32: JWT Vulnerability → Privilege Escalation
        self.rules.append(ProbabilisticRule(
            rule_id="JWT_PRIVILEGE_ESCALATION",
            name="JWT None Algorithm/Bypass → Auth Bypass",
            base_probability=0.9,
            boosting_factors=[
                ("jwt_vuln", lambda s, t: any(x in s.name.lower() for x in ["jwt", "json web token", "none algorithm", "algorithm confusion", "signature bypass"]), 1.9),
                ("privilege_endpoint", lambda s, t: any(x in (t.url or "").lower() for x in ["/admin", "/privilege", "/role", "/manage"]), 1.8),
                ("authorization_context", lambda s, t: any(x in t.name.lower() for x in ["authorization", "privilege", "escalation", "admin"]), 1.7),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 33: IDOR → Unauthorized Data Access
        self.rules.append(ProbabilisticRule(
            rule_id="IDOR_DATA_ACCESS",
            name="IDOR → Unauthorized Data Access",
            base_probability=0.9,
            boosting_factors=[
                ("idor_present", lambda s, t: any(x in s.name.lower() for x in ["idor", "insecure direct object", "broken access control", "authorization bypass"]), 1.9),
                ("data_endpoint", lambda s, t: any(x in (t.url or "").lower() for x in ["/user", "/profile", "/account", "/data", "/document"]), 1.8),
                ("pii_context", lambda s, t: any(x in t.name.lower() for x in ["user data", "pii", "sensitive information", "personal"]), 1.7),
                ("numeric_id", lambda s, t: self._has_sequential_ids(s), 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Note: Rule 34 (XSS_COOKIE_THEFT) merged into Rule 3 (XSS_SESSION_HIJACK)

        # ========== API SECURITY CHAIN RULES (OWASP API TOP 10) ==========

        # Rule 35: Mass Assignment → Privilege Escalation
        self.rules.append(ProbabilisticRule(
            rule_id="MASS_ASSIGNMENT_PRIVILEGE",
            name="Mass Assignment → Privilege Escalation",
            base_probability=0.85,
            boosting_factors=[
                ("mass_assignment", lambda s, t: any(x in s.name.lower() for x in ["mass assignment", "auto-binding", "parameter pollution"]), 1.9),
                ("role_endpoint", lambda s, t: any(x in (t.url or "").lower() for x in ["/user", "/profile", "/account", "/update"]), 1.7),
                ("privilege_context", lambda s, t: any(x in t.name.lower() for x in ["role", "admin", "privilege", "permission"]), 1.8),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 36: GraphQL Introspection → Information Disclosure
        self.rules.append(ProbabilisticRule(
            rule_id="GRAPHQL_INTROSPECTION_DATA",
            name="GraphQL Introspection → Info Disclosure → Data Access",
            base_probability=0.75,
            boosting_factors=[
                ("graphql_introspection", lambda s, t: any(x in s.name.lower() for x in ["graphql introspection", "graphql", "introspection enabled"]), 1.8),
                ("data_disclosure", lambda s, t: any(x in t.name.lower() for x in ["sensitive data", "internal", "hidden fields", "information disclosure"]), 1.7),
                ("graphql_endpoint", lambda s, t: "/graphql" in (s.url or "").lower(), 1.6),
            ],
            penalty_factors=[
                ("introspection_disabled", lambda s, t: "disabled" in (s.description or "").lower() if s.description else False, 0.3),
            ],
            min_taxonomy_match=None
        ))

        # Rule 37: API Key Exposure → API Abuse
        self.rules.append(ProbabilisticRule(
            rule_id="API_KEY_EXPOSURE_ABUSE",
            name="API Key in URL/Response → Account Compromise",
            base_probability=0.85,
            boosting_factors=[
                ("api_key_exposed", lambda s, t: any(x in s.name.lower() for x in ["api key", "key in url", "key exposure", "sensitive data in response"]), 1.9),
                ("api_endpoint", lambda s, t: "/api/" in (t.url or ""), 1.7),
                ("auth_context", lambda s, t: any(x in t.name.lower() for x in ["authentication", "authorization", "api"]), 1.6),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Note: Rule 38 (API_NO_RATE_LIMIT_BRUTEFORCE) merged into Rule 13 (NO_RATE_LIMIT_BRUTEFORCE)

        # Rule 39: API Versioning → Old API Vulnerability
        self.rules.append(ProbabilisticRule(
            rule_id="API_VERSION_VULN",
            name="Old API Version → Less Secured Endpoint",
            base_probability=0.7,
            boosting_factors=[
                ("old_api_version", lambda s, t: any(x in (s.url or "") for x in ["/api/v1/", "/api/v0/", "/api/beta/"]), 1.6),
                ("newer_version_exists", lambda s, t: "/api/v2/" in (t.url or "") or "/api/v3/" in (t.url or ""), 1.5),
                ("same_endpoint_path", lambda s, t: self._same_endpoint_path(s, t), 1.7),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 40: Swagger/OpenAPI Exposure → Hidden Endpoints
        self.rules.append(ProbabilisticRule(
            rule_id="SWAGGER_HIDDEN_ENDPOINTS",
            name="Swagger/OpenAPI Exposure → Hidden API Discovery",
            base_probability=0.7,
            boosting_factors=[
                ("swagger_exposed", lambda s, t: any(x in s.name.lower() for x in ["swagger", "openapi", "api documentation", "swagger ui"]), 1.8),
                ("hidden_endpoint", lambda s, t: any(x in (t.url or "").lower() for x in ["/internal", "/admin", "/debug", "/test"]), 1.7),
                ("api_context", lambda s, t: "/api/" in (t.url or ""), 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # ========== FILE & PATH TRAVERSAL CHAIN RULES ==========

        # Rule 41: Path Traversal → Credential File Access
        self.rules.append(ProbabilisticRule(
            rule_id="PATH_TRAVERSAL_CREDENTIALS",
            name="Path Traversal → Credential/Config File Access",
            base_probability=0.8,
            boosting_factors=[
                ("path_traversal", lambda s, t: any(x in s.name.lower() for x in ["path traversal", "directory traversal", "lfi", "local file inclusion"]), 1.9),
                ("credential_file", lambda s, t: any(x in t.name.lower() for x in ["credential", "config", "password", "key", ".env"]), 1.8),
                ("file_parameter", lambda s, t: any(x in (s.param or "").lower() for x in ["file", "path", "page", "include", "template", "document"]), 1.6),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 42: LFI → Log Poisoning → RCE
        self.rules.append(ProbabilisticRule(
            rule_id="LFI_LOG_POISONING_RCE",
            name="LFI + Log Poisoning = RCE",
            base_probability=0.6,
            boosting_factors=[
                ("lfi_present", lambda s, t: any(x in s.name.lower() for x in ["lfi", "local file inclusion", "path traversal"]), 1.8),
                ("log_access", lambda s, t: any(x in t.name.lower() for x in ["log", "access log", "error log", "apache"]), 1.7),
                ("rce_potential", lambda s, t: any(x in t.name.lower() for x in ["rce", "code execution"]), 1.9),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 43: File Upload → Web Shell → RCE
        self.rules.append(ProbabilisticRule(
            rule_id="FILE_UPLOAD_WEBSHELL_RCE",
            name="Unrestricted File Upload → Web Shell → RCE",
            base_probability=0.9,
            boosting_factors=[
                ("file_upload", lambda s, t: any(x in s.name.lower() for x in ["file upload", "unrestricted upload", "arbitrary file upload"]), 2.0),
                ("rce_context", lambda s, t: any(x in t.name.lower() for x in ["rce", "code execution", "web shell", "server"]), 1.9),
                ("upload_endpoint", lambda s, t: any(x in (s.url or "").lower() for x in ["/upload", "/file", "/attachment"]), 1.6),
            ],
            penalty_factors=[
                ("file_validation", lambda s, t: "validation" in (s.description or "").lower() if s.description else False, 0.5),
            ],
            min_taxonomy_match=None
        ))

        # Rule 44: Directory Listing → Information Disclosure
        self.rules.append(ProbabilisticRule(
            rule_id="DIRECTORY_LISTING_INFO",
            name="Directory Listing → Info Disclosure → Further Attacks",
            base_probability=0.7,
            boosting_factors=[
                ("dir_listing", lambda s, t: any(x in s.name.lower() for x in ["directory listing", "directory browsing", "index of"]), 1.7),
                ("sensitive_info", lambda s, t: any(x in t.name.lower() for x in ["information disclosure", "source code", "backup", "config"]), 1.8),
                ("backup_file", lambda s, t: any(x in (t.url or "").lower() for x in [".bak", ".old", ".sql", ".zip", "backup"]), 1.6),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 45: .git Exposure → Source Code → Credentials
        self.rules.append(ProbabilisticRule(
            rule_id="GIT_EXPOSURE_CREDENTIALS",
            name=".git Exposure → Source Code → Credentials/API Keys",
            base_probability=0.9,
            boosting_factors=[
                ("git_exposed", lambda s, t: any(x in s.name.lower() for x in ["git disclosure", ".git exposed", "git repository"]), 2.0),
                ("credentials", lambda s, t: any(x in t.name.lower() for x in ["source code", "credentials", "api keys", "password"]), 1.9),
                ("git_path", lambda s, t: ".git" in (s.url or ""), 1.7),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # ========== INFORMATION DISCLOSURE CHAIN RULES ==========

        # Rule 46: Verbose Error Messages → SQL Injection Exploitation
        self.rules.append(ProbabilisticRule(
            rule_id="ERROR_MESSAGE_SQLI",
            name="Verbose Error Messages → Enhanced SQLi Exploitation",
            base_probability=0.75,
            boosting_factors=[
                ("error_disclosure", lambda s, t: any(x in s.name.lower() for x in ["application error", "error message", "stack trace", "debug information"]), 1.7),
                ("sqli_present", lambda s, t: any(x in t.name.lower() for x in ["sql injection", "sqli", "database"]), 1.9),
                ("database_error", lambda s, t: any(x in (s.description or "").lower() for x in ["mysql", "postgresql", "mssql", "oracle", "syntax error"]) if s.description else False, 1.6),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 47: Technology Disclosure → Version-Specific Exploit
        self.rules.append(ProbabilisticRule(
            rule_id="TECH_DISCLOSURE_CVE",
            name="Technology/Version Disclosure → Known CVE Exploit",
            base_probability=0.6,
            boosting_factors=[
                ("version_disclosure", lambda s, t: any(x in s.name.lower() for x in ["server header", "x-powered-by", "version disclosure", "software version"]), 1.6),
                ("cve_context", lambda s, t: any(x in t.name.lower() for x in ["cve", "vulnerability", "exploit", "known issue"]), 1.7),
                ("specific_version", lambda s, t: any(char.isdigit() for char in (s.description or "")) if s.description else False, 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 48: Debug Endpoint → RCE/Info Leak
        self.rules.append(ProbabilisticRule(
            rule_id="DEBUG_ENDPOINT_RCE",
            name="Debug/Actuator Endpoint Exposed → RCE/Secrets",
            base_probability=0.85,
            boosting_factors=[
                ("debug_endpoint", lambda s, t: any(x in s.name.lower() for x in ["debug", "actuator", "spring actuator", "development endpoint"]), 1.9),
                ("critical_context", lambda s, t: any(x in t.name.lower() for x in ["rce", "credential", "internal", "environment", "secret"]), 1.9),
                ("actuator_path", lambda s, t: "/actuator/" in (s.url or ""), 1.7),
            ],
            penalty_factors=[
                ("auth_required", lambda s, t: "authenticated" in (s.description or "").lower() if s.description else False, 0.5),
            ],
            min_taxonomy_match=None
        ))

        # Rule 49: Verbose Application Errors → Attack Surface Mapping
        self.rules.append(ProbabilisticRule(
            rule_id="VERBOSE_ERROR_ATTACK_SURFACE",
            name="Verbose Errors → Attack Surface Mapping → Targeted Attack",
            base_probability=0.7,
            boosting_factors=[
                ("verbose_errors", lambda s, t: any(x in s.name.lower() for x in ["error", "stack trace", "debug", "verbose"]), 1.6),
                ("attack_vector", lambda s, t: any(x in t.name.lower() for x in ["injection", "traversal", "upload", "inclusion"]), 1.7),
                ("framework_info", lambda s, t: any(x in (s.description or "").lower() for x in ["framework", "library", "module"]) if s.description else False, 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # ========== MODERN ATTACK PATTERNS (2023-2025) ==========

        # Rule 50: OAuth Misconfiguration → Account Takeover
        self.rules.append(ProbabilisticRule(
            rule_id="OAUTH_MISCONFIGURATION_TAKEOVER",
            name="OAuth/OIDC Misconfiguration → Account Takeover",
            base_probability=0.8,
            boosting_factors=[
                ("oauth_issue", lambda s, t: any(x in s.name.lower() for x in ["oauth", "oidc", "open redirect", "state parameter"]), 1.8),
                ("takeover_context", lambda s, t: any(x in t.name.lower() for x in ["account takeover", "token theft", "credential"]), 1.7),
                ("oauth_endpoint", lambda s, t: any(x in (s.url or "").lower() for x in ["/oauth", "/auth", "/callback", "/redirect"]), 1.6),
            ],
            penalty_factors=[
                ("state_validated", lambda s, t: "state" in (s.description or "").lower() and "validated" in (s.description or "").lower() if s.description else False, 0.4),
            ],
            min_taxonomy_match=None
        ))

        # Rule 51: Kubernetes API Exposure → Cluster Compromise
        self.rules.append(ProbabilisticRule(
            rule_id="K8S_API_CLUSTER_COMPROMISE",
            name="K8s API Exposure → Cluster Compromise",
            base_probability=0.85,
            boosting_factors=[
                ("k8s_exposed", lambda s, t: any(x in s.name.lower() for x in ["kubernetes api", "k8s", "kubectl", "kube-apiserver"]), 2.0),
                ("cluster_access", lambda s, t: any(x in t.name.lower() for x in ["cluster", "container escape", "secrets", "pods"]), 1.9),
                ("k8s_endpoint", lambda s, t: any(x in (s.url or "").lower() for x in ["/api/v1", "/apis", "/healthz", "/version"]), 1.7),
            ],
            penalty_factors=[
                ("auth_required", lambda s, t: "authentication" in (s.description or "").lower() if s.description else False, 0.5),
            ],
            min_taxonomy_match=None
        ))

        # Rule 52: Prototype Pollution → XSS/RCE
        self.rules.append(ProbabilisticRule(
            rule_id="PROTOTYPE_POLLUTION_EXPLOITATION",
            name="Prototype Pollution → XSS/RCE",
            base_probability=0.7,
            boosting_factors=[
                ("prototype_pollution", lambda s, t: any(x in s.name.lower() for x in ["prototype pollution", "javascript", "__proto__", "constructor.prototype"]), 1.9),
                ("exploitation", lambda s, t: any(x in t.name.lower() for x in ["xss", "rce", "denial of service", "code execution"]), 1.8),
                ("js_context", lambda s, t: any(x in (s.url or "").lower() for x in [".js", "/api", "/graphql"]), 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 53: WebSocket Vulnerabilities → Data Theft
        self.rules.append(ProbabilisticRule(
            rule_id="WEBSOCKET_DATA_THEFT",
            name="WebSocket CSWSH/Injection → Data Theft",
            base_probability=0.7,
            boosting_factors=[
                ("websocket_vuln", lambda s, t: any(x in s.name.lower() for x in ["websocket", "ws://", "wss://", "cswsh"]), 1.8),
                ("data_access", lambda s, t: any(x in t.name.lower() for x in ["data theft", "injection", "sensitive data"]), 1.7),
                ("ws_endpoint", lambda s, t: "ws://" in (s.url or "") or "wss://" in (s.url or ""), 1.6),
            ],
            penalty_factors=[
                ("origin_validated", lambda s, t: "origin" in (s.description or "").lower() and "check" in (s.description or "").lower() if s.description else False, 0.4),
            ],
            min_taxonomy_match=None
        ))

        # Rule 54: Node.js Specific → RCE
        self.rules.append(ProbabilisticRule(
            rule_id="NODEJS_SPECIFIC_RCE",
            name="Node.js vm.runInNewContext/require → RCE",
            base_probability=0.75,
            boosting_factors=[
                ("nodejs_vuln", lambda s, t: any(x in s.name.lower() for x in ["nodejs", "node.js", "javascript server", "vm.runincontext"]), 1.9),
                ("rce_context", lambda s, t: any(x in t.name.lower() for x in ["rce", "code execution", "server"]), 1.9),
                ("nodejs_indicators", lambda s, t: any(x in (s.url or "").lower() for x in [".js", "/node_modules"]), 1.5),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 55: CI/CD Exposure → Supply Chain Attack
        self.rules.append(ProbabilisticRule(
            rule_id="CICD_SUPPLY_CHAIN",
            name="CI/CD Exposure → Supply Chain/Secrets Theft",
            base_probability=0.8,
            boosting_factors=[
                ("cicd_exposed", lambda s, t: any(x in s.name.lower() for x in ["github actions", "gitlab ci", "jenkins", "cicd", "ci/cd"]), 1.9),
                ("supply_chain", lambda s, t: any(x in t.name.lower() for x in ["secrets", "supply chain", "code execution", "credentials"]), 1.9),
                ("cicd_files", lambda s, t: any(x in (s.url or "").lower() for x in [".github/workflows", ".gitlab-ci.yml", "jenkinsfile", ".circleci"]), 1.7),
            ],
            penalty_factors=[],
            min_taxonomy_match=None
        ))

        # Rule 56: LLM/AI Prompt Injection → Data Exfiltration
        self.rules.append(ProbabilisticRule(
            rule_id="LLM_PROMPT_INJECTION_EXFIL",
            name="LLM Prompt Injection → Data/Action Exfiltration",
            base_probability=0.7,
            boosting_factors=[
                ("llm_vuln", lambda s, t: any(x in s.name.lower() for x in ["llm", "chatbot", "ai assistant", "openai", "gpt", "prompt injection"]), 1.8),
                ("data_exfil", lambda s, t: any(x in t.name.lower() for x in ["data leak", "unauthorized action", "prompt injection", "sensitive data"]), 1.8),
                ("llm_endpoint", lambda s, t: any(x in (s.url or "").lower() for x in ["/chat", "/ai", "/completion", "/generate", "/assistant"]), 1.7),
            ],
            penalty_factors=[
                ("input_sanitization", lambda s, t: "sanitiz" in (s.description or "").lower() if s.description else False, 0.5),
            ],
            min_taxonomy_match=None
        ))

    def calculate_link_probability(
        self,
        source: 'Vulnerability',
        target: 'Vulnerability'
    ) -> List[Tuple[str, float, Dict]]:
        """
        Calculates link probability between two vulnerabilities.
        Returns list of (rule_id, probability, metadata) for each matching rule.
        """
        results = []

        source_node = self.taxonomy.classify(source.name)
        target_node = self.taxonomy.classify(target.name)

        for rule in self.rules:
            # Check minimum taxonomy match level (if enabled)
            if self.config.enable_taxonomy_matching:
                if not self._check_taxonomy_match(source_node, target_node, rule.min_taxonomy_match):
                    continue

            # Initialize metadata for debugging
            metadata = {
                "factors": [],
                "base_probability": rule.base_probability,
                "rule_name": rule.name
            }

            # Calculate total boost multiplier
            total_boost = 1.0
            for factor_name, check_fn, multiplier in rule.boosting_factors:
                try:
                    if check_fn(source, target):
                        total_boost *= multiplier
                        metadata["factors"].append(f"+{factor_name}")
                except Exception as e:
                    error_key = f"{rule.rule_id}:boost:{factor_name}"
                    self.error_stats[error_key] += 1
                    logger.debug("Error in boosting factor %s (rule %s): %s", factor_name, rule.rule_id, e)

            # Cap boost multiplier to prevent probability overflow
            total_boost = min(total_boost, self.config.max_boost_multiplier)
            metadata["total_boost"] = total_boost

            # Apply boost to base probability
            probability = rule.base_probability * total_boost
            metadata["after_boost"] = probability

            # Apply penalty factors
            total_penalty = 1.0
            for factor_name, check_fn, multiplier in rule.penalty_factors:
                try:
                    if check_fn(source, target):
                        total_penalty *= multiplier
                        metadata["factors"].append(f"-{factor_name}")
                except Exception as e:
                    error_key = f"{rule.rule_id}:penalty:{factor_name}"
                    self.error_stats[error_key] += 1
                    logger.debug("Error in penalty factor %s (rule %s): %s", factor_name, rule.rule_id, e)

            probability *= total_penalty
            metadata["total_penalty"] = total_penalty
            metadata["after_penalty"] = probability

            # Add semantic similarity (if enabled)
            if self.config.enable_semantic_similarity:
                semantic_sim = self.taxonomy.get_similarity(source.name, target.name)
                semantic_multiplier = (0.5 + semantic_sim * 0.5)  # From 0.5 to 1.0
                probability *= semantic_multiplier
                metadata["semantic_similarity"] = semantic_sim
                metadata["after_semantic"] = probability

            # Add enable probability (if enabled)
            if self.config.enable_semantic_similarity:
                enable_prob = self.taxonomy.can_enable(source.name, target.name)
                if enable_prob > 0:
                    enable_multiplier = (1.0 + enable_prob * 0.5)
                    probability *= enable_multiplier
                    metadata["enable_probability"] = enable_prob
                    metadata["after_enable"] = probability

            # Normalize to [0, 1] range
            probability = min(max(probability, 0.0), 1.0)
            metadata["final_probability"] = probability

            # Add result if probability above configured threshold
            if probability >= self.config.min_link_probability:
                results.append((rule.rule_id, probability, metadata))

        return results

    # Helper methods
    def _same_domain(self, s: 'Vulnerability', t: 'Vulnerability') -> bool:
        try:
            return urlparse(s.url).netloc == urlparse(t.url).netloc
        except:
            return False

    def _same_endpoint(self, s: 'Vulnerability', t: 'Vulnerability') -> bool:
        try:
            return urlparse(s.url).path == urlparse(t.url).path
        except:
            return False

    def _same_path_prefix(self, s: 'Vulnerability', t: 'Vulnerability') -> bool:
        try:
            s_path = urlparse(s.url).path.split('/')[1:2]
            t_path = urlparse(t.url).path.split('/')[1:2]
            return s_path == t_path and s_path
        except:
            return False

    def _same_endpoint_path(self, s: 'Vulnerability', t: 'Vulnerability') -> bool:
        """
        Check if two API endpoints have the same path structure ignoring version numbers.
        Example: /api/v1/users and /api/v2/users should return True
        """
        try:
            s_path = urlparse(s.url).path
            t_path = urlparse(t.url).path

            # Remove version patterns using precompiled regex
            s_normalized = self.VERSION_PATTERN.sub('/', s_path)
            s_normalized = self.STAGE_PATTERN.sub('/', s_normalized)

            t_normalized = self.VERSION_PATTERN.sub('/', t_path)
            t_normalized = self.STAGE_PATTERN.sub('/', t_normalized)

            return s_normalized == t_normalized
        except (ValueError, AttributeError) as e:
            logger.debug("Error in _same_endpoint_path: s=%s, t=%s, error=%s", s.url, t.url, e)
            return False

    def _has_httponly_issue(self, s: 'Vulnerability', t: 'Vulnerability') -> bool:
        # Check if there's HttpOnly issue in scope
        return "httponly" in t.name.lower() or "httponly" in s.name.lower()

    def _reveals_paths(self, v: 'Vulnerability') -> bool:
        keywords = ["directory", "listing", "path", "traversal", "disclosure"]
        return any(kw in v.name.lower() for kw in keywords)

    def _reveals_technology(self, v: 'Vulnerability') -> bool:
        keywords = ["version", "server", "x-powered", "technology", "fingerprint"]
        return any(kw in v.name.lower() for kw in keywords)

    def _needs_information(self, v: 'Vulnerability') -> bool:
        # Vulnerabilities that require preliminary information
        keywords = ["injection", "rce", "command", "upload"]
        return any(kw in v.name.lower() for kw in keywords)

    def _different_auth_levels(self, s: 'Vulnerability', t: 'Vulnerability') -> bool:
        # Heuristic: different URL prefixes may mean different access levels
        public_prefixes = ["/", "/public", "/api/v1"]
        admin_prefixes = ["/admin", "/dashboard", "/manage", "/internal"]

        s_is_public = any(p in (s.url or "") for p in public_prefixes)
        t_is_admin = any(p in (t.url or "") for p in admin_prefixes)

        return s_is_public and t_is_admin

    def _related_protections(self, s: 'Vulnerability', t: 'Vulnerability') -> bool:
        """Check if two header issues protect against related attacks"""
        # CSP + X-Frame-Options both protect against client-side attacks
        client_protection = ["csp", "frame", "clickjack"]
        # HSTS + Secure cookies protect transport
        transport_protection = ["hsts", "secure", "transport"]

        s_lower = s.name.lower()
        t_lower = t.name.lower()

        # Check if both are in same protection category
        s_in_client = any(p in s_lower for p in client_protection)
        t_in_client = any(p in t_lower for p in client_protection)

        s_in_transport = any(p in s_lower for p in transport_protection)
        t_in_transport = any(p in t_lower for p in transport_protection)

        return (s_in_client and t_in_client) or (s_in_transport and t_in_transport)

    # ========== HELPER METHODS FOR MODERN VULNERABILITIES ==========

    def _is_cloud_environment(self, s: 'Vulnerability', t: 'Vulnerability') -> bool:
        """Check if running in cloud environment (AWS, Azure, GCP)"""
        cloud_indicators = [
            "aws", "amazon", "ec2", "s3", "lambda",
            "azure", "microsoft",
            "gcp", "google cloud", "gke",
            "kubernetes", "k8s", "docker", "container"
        ]

        s_url = (s.url or "").lower()
        t_url = (t.url or "").lower()
        s_desc = (s.description or "").lower() if s.description else ""
        t_desc = (t.description or "").lower() if t.description else ""

        combined = f"{s_url} {t_url} {s_desc} {t_desc}"
        return any(ind in combined for ind in cloud_indicators)

    def _has_sequential_ids(self, v: 'Vulnerability') -> bool:
        """Check if vulnerability URL contains sequential/numeric IDs (indication of IDOR/BOLA)"""
        url = v.url or ""
        try:
            # Use precompiled patterns for performance
            return any(pattern.search(url) for pattern in self.NUMERIC_ID_PATTERNS)
        except (ValueError, AttributeError) as e:
            logger.debug("Error in _has_sequential_ids: url=%s, error=%s", url, e)
            return False

    def _check_taxonomy_match(
        self,
        source_node,
        target_node,
        min_level: str
    ) -> bool:
        if not source_node or not target_node:
            return False

        # None means no taxonomy matching required (for cross-category modern chains)
        if min_level is None:
            return True

        if min_level == "category":
            return source_node.category == target_node.category
        elif min_level == "subcategory":
            return (source_node.category == target_node.category and
                    source_node.subcategory == target_node.subcategory)
        elif min_level == "specific":
            return source_node.specific_type == target_node.specific_type
        return True

    def get_error_summary(self) -> Dict[str, int]:
        """Returns error statistics for debugging"""
        return dict(self.error_stats)

    def __repr__(self) -> str:
        return f"ProbabilisticRuleEngine({len(self.rules)} rules)"
